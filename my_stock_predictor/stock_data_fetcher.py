#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ•°æ®è·å–æ¨¡å—
æ”¯æŒä»å¤šä¸ªæ•°æ®æºè·å–è‚¡ç¥¨æ•°æ®å¹¶ä¿å­˜ä¸ºKronosæ ¼å¼

ä½¿ç”¨æ–¹æ³•:
    python stock_data_fetcher.py --symbol 000001 --source akshare --period 5
    python stock_data_fetcher.py --symbol AAPL --source yfinance --period 5m --days 365
"""

import argparse
import pandas as pd
import numpy as np
import requests
import json
import time
import os
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

from constants import (
    TRADING_MINUTES_PER_DAY,
    TRADING_DAYS_RATIO,
    CHUNK_DAYS_MAP,
    MAX_ATTEMPTS_MAP,
    REQUEST_DELAY_MAP,
    DATA_AMOUNT_CHECK_RATIO,
    MIN_DATA_FOR_CHUNK,
    MAX_CONSECUTIVE_EMPTY
)

class StockDataFetcher:
    """è‚¡ç¥¨æ•°æ®è·å–å™¨"""
    
    # ç±»å˜é‡ï¼šbaostock ç™»å½•çŠ¶æ€
    _baostock_logged_in = False
    
    def __init__(self, data_dir="my_stock_predictor/stock_data"):
        """
        åˆå§‹åŒ–æ•°æ®è·å–å™¨
        
        Args:
            data_dir (str): æ•°æ®ä¿å­˜ç›®å½•
        """
        self.data_dir = data_dir
        self.ensure_data_dir()
    
    @classmethod
    def _ensure_baostock_login(cls):
        """ç¡®ä¿ baostock å·²ç™»å½•ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
        if not cls._baostock_logged_in:
            try:
                import baostock as bs
                lg = bs.login()
                if lg.error_code == '0':
                    cls._baostock_logged_in = True
                    print("âœ… baostock ç™»å½•æˆåŠŸ")
                else:
                    print(f"âš ï¸ baostock ç™»å½•å¤±è´¥: {lg.error_msg}")
                    return False
            except ImportError:
                print("é”™è¯¯: è¯·å…ˆå®‰è£… baostock: pip install baostock")
                return False
            except Exception as e:
                print(f"baostock ç™»å½•å¼‚å¸¸: {e}")
                return False
        return True
        
    def ensure_data_dir(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            print(f"åˆ›å»ºæ•°æ®ç›®å½•: {self.data_dir}")

    def _format_period_label(self, period):
        """ç»Ÿä¸€ç”Ÿæˆç”¨äºä¿å­˜æ–‡ä»¶çš„å‘¨æœŸå­—ç¬¦ä¸²"""
        if period is None:
            return 'custom'

        period_str = str(period).strip()

        if period_str.upper() == 'D':
            return 'daily'

        lower_period = period_str.lower()
        if lower_period.endswith(('m', 'h', 'd')):
            return lower_period

        if period_str.isdigit():
            return f"{period_str}min"

        return lower_period
    
    def fetch_from_akshare(self, symbol, start_date=None, end_date=None, period='5'):
        """
        ä½¿ç”¨akshareè·å–è‚¡ç¥¨æ•°æ®
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚'000001'
            start_date (str): å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            end_date (str): ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            period (str): å‘¨æœŸï¼Œ'1'=1åˆ†é’Ÿ, '5'=5åˆ†é’Ÿ, '15'=15åˆ†é’Ÿ, '30'=30åˆ†é’Ÿ, '60'=1å°æ—¶, 'D'=æ—¥çº¿
            
        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ®
        """
        try:
            import akshare as ak
            
            # è·å–è‚¡ç¥¨åç§°
            stock_name = "Unknown"
            try:
                stock_info_df = ak.stock_individual_info_em(symbol=symbol)
                stock_name = stock_info_df.loc[stock_info_df['item'] == 'è‚¡ç¥¨ç®€ç§°', 'value'].values[0]
                print(f"è·å–åˆ°è‚¡ç¥¨åç§°: {stock_name}")
            except Exception as e:
                print(f"è­¦å‘Š: è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")

            # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
            if end_date is None:
                end_date = datetime.now().strftime('%Y-%m-%d')
            if start_date is None:
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            print(f"æ­£åœ¨è·å– {symbol} çš„ {period}åˆ†é’Ÿæ•°æ®...")
            print(f"æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
            
            # è·å–è‚¡ç¥¨æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    if period == 'D':
                        # æ—¥çº¿æ•°æ®
                        df = ak.stock_zh_a_hist(symbol=symbol, period="daily",
                                              start_date=start_date, end_date=end_date,
                                              adjust="qfq")
                    else:
                        # åˆ†é’Ÿæ•°æ®
                        df = ak.stock_zh_a_hist_min_em(symbol=symbol, period=period,
                                                     start_date=start_date, end_date=end_date,
                                                     adjust='qfq')
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                except Exception as e:
                    if attempt < max_retries - 1:
                        print(f"ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{max_retries - attempt - 1}ç§’åé‡è¯•...")
                        time.sleep(max_retries - attempt)  # é€’å¢å»¶è¿Ÿ
                    else:
                        print(f"é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥: {e}")
                        raise
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…Kronosæ ¼å¼
            column_mapping = {
                'æ—¥æœŸ': 'timestamps',
                'æ—¶é—´': 'timestamps',
                'å¼€ç›˜': 'open',
                'æœ€é«˜': 'high', 
                'æœ€ä½': 'low',
                'æ”¶ç›˜': 'close',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount'
            }
            
            df = df.rename(columns=column_mapping)
            
            # å¤„ç†æ—¶é—´æˆ³
            if 'timestamps' in df.columns:
                if 'æ—¥æœŸ' in df.columns and 'æ—¶é—´' in df.columns:
                    # åˆå¹¶æ—¥æœŸå’Œæ—¶é—´
                    df['timestamps'] = df['æ—¥æœŸ'] + ' ' + df['æ—¶é—´']
                elif 'æ—¥æœŸ' in df.columns:
                    df['timestamps'] = df['æ—¥æœŸ'] + ' 00:00:00'
                
                df['timestamps'] = pd.to_datetime(df['timestamps'])
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
            required_columns = ['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']
            for col in required_columns:
                if col not in df.columns:
                    if col == 'amount':
                        # å¦‚æœæ²¡æœ‰æˆäº¤é¢ï¼Œç”¨æˆäº¤é‡*æ”¶ç›˜ä»·ä¼°ç®—
                        df['amount'] = df['volume'] * df['close']
                    else:
                        print(f"è­¦å‘Š: ç¼ºå°‘åˆ— {col}")
            
            # é€‰æ‹©å¹¶æ’åºåˆ—
            df = df[required_columns].copy()
            df = df.sort_values('timestamps').reset_index(drop=True)
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'amount']
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # åˆ é™¤æ— æ•ˆæ•°æ®
            df = df.dropna()
            
            print(f"æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
            return df, stock_name
            
        except ImportError:
            print("é”™è¯¯: è¯·å…ˆå®‰è£…akshare: pip install akshare")
            return None, None
        except Exception as e:
            print(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
            return None, None
    
    def fetch_from_yfinance(self, symbol, start_date=None, end_date=None, interval='5m'):
        """
        ä½¿ç”¨yfinanceè·å–è‚¡ç¥¨æ•°æ®ï¼ˆé€‚ç”¨äºç¾è‚¡ç­‰ï¼‰
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚'AAPL'
            start_date (str): å¼€å§‹æ—¥æœŸ
            end_date (str): ç»“æŸæ—¥æœŸ
            interval (str): æ—¶é—´é—´éš”ï¼Œ'1m', '5m', '15m', '30m', '1h', '1d'
            
        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ®
        """
        try:
            import yfinance as yf
            
            # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
            if end_date is None:
                end_date = datetime.now().strftime('%Y-%m-%d')
            if start_date is None:
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            print(f"æ­£åœ¨è·å– {symbol} çš„æ•°æ®...")
            print(f"æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
            
            # è·å–è‚¡ç¥¨ Ticker
            ticker = yf.Ticker(symbol)

            # è·å–è‚¡ç¥¨åç§°
            stock_name = "Unknown"
            try:
                info = ticker.info
                stock_name = info.get('shortName', info.get('longName', 'Unknown'))
                print(f"è·å–åˆ°è‚¡ç¥¨åç§°: {stock_name}")
            except Exception as e:
                print(f"è­¦å‘Š: è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")

            # è·å–è‚¡ç¥¨æ•°æ®
            df = ticker.history(start=start_date, end=end_date, interval=interval)
            
            # é‡ç½®ç´¢å¼•ï¼Œå°†æ—¥æœŸå˜ä¸ºåˆ—
            df = df.reset_index()
            
            # é‡å‘½ååˆ—
            column_mapping = {
                'Datetime': 'timestamps',
                'Date': 'timestamps',
                'Open': 'open',
                'High': 'high',
                'Low': 'low', 
                'Close': 'close',
                'Volume': 'volume'
            }
            
            df = df.rename(columns=column_mapping)
            
            # æ·»åŠ æˆäº¤é¢åˆ—ï¼ˆç”¨æˆäº¤é‡*æ”¶ç›˜ä»·ä¼°ç®—ï¼‰
            df['amount'] = df['volume'] * df['close']
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
            required_columns = ['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']
            df = df[required_columns].copy()
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'amount']
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # åˆ é™¤æ— æ•ˆæ•°æ®
            df = df.dropna()
            
            print(f"æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
            return df, stock_name
            
        except ImportError:
            print("é”™è¯¯: è¯·å…ˆå®‰è£…yfinance: pip install yfinance")
            return None, None
        except Exception as e:
            print(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
            return None, None

    def fetch_from_baostock(self, symbol, start_date=None, end_date=None, period='5'):
        """
        ä½¿ç”¨baostockè·å–è‚¡ç¥¨æ•°æ®ï¼ˆç™¾åº¦é‡‘èæ•°æ®ï¼‰

        æ•°æ®ç‰¹ç‚¹:
        - ç™¾åº¦é‡‘èæ•°æ®å¹³å°
        - æ•°æ®è´¨é‡è¾ƒé«˜ï¼Œæ”¯æŒåˆ†é’Ÿçº¿
        - éœ€è¦æ³¨å†Œè·å–token
        - æ”¯æŒAè‚¡ã€æŒ‡æ•°ç­‰

        Args:
            symbol (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚'sh.600000' (æµ¦å‘é“¶è¡Œ)
            start_date (str): å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            end_date (str): ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            period (str): å‘¨æœŸï¼Œ'5'è¡¨ç¤º5åˆ†é’Ÿ

        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ®
        """
        try:
            import baostock as bs

            # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
            if end_date is None:
                end_date = datetime.now().strftime('%Y-%m-%d')
            if start_date is None:
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')

            print(f"æ­£åœ¨è·å– {symbol} çš„æ•°æ® (baostock)...")
            print(f"æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")

            # ç¡®ä¿å·²ç™»å½•ï¼ˆä½¿ç”¨å•ä¾‹æ¨¡å¼é¿å…é‡å¤ç™»å½•ï¼‰
            if not self._ensure_baostock_login():
                return None, None

            try:
                # è·å–è‚¡ç¥¨æ•°æ®
                # æ³¨æ„ï¼šbaostockçš„è‚¡ç¥¨ä»£ç æ ¼å¼éœ€è¦è½¬æ¢
                if '.' not in symbol:
                    # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œæ·»åŠ å¸‚åœºå‰ç¼€
                    if symbol.startswith(('000', '001', '002', '003', '300', '301')):
                        symbol = f"sz.{symbol}"  # åˆ›ä¸šæ¿/ä¸­å°æ¿
                    elif symbol.startswith(('600', '601', '603', '605', '688')):
                        symbol = f"sh.{symbol}"  # ä¸»æ¿/ç§‘åˆ›æ¿
                    else:
                        symbol = f"sh.{symbol}"  # é»˜è®¤æ²ªå¸‚

                # æ ¹æ®å‘¨æœŸè®¾ç½®frequency
                freq_map = {
                    '1': '1',
                    '5': '5',
                    '15': '15',
                    '30': '30',
                    '60': '60',
                    'D': 'd'
                }
                frequency = freq_map.get(period, '5')

                rs = bs.query_history_k_data_plus(
                    symbol,
                    "date,time,open,high,low,close,volume,amount",
                    start_date=start_date,
                    end_date=end_date,
                    frequency=frequency,
                    adjustflag="3"  # å‰å¤æƒè°ƒæ•´ (æ›´å¸¸ç”¨)
                )

                if rs.error_code != '0':
                    print(f"è·å–æ•°æ®å¤±è´¥: {rs.error_msg}")
                    return None, None

                # å¤„ç†æ•°æ®
                data_list = []
                while (rs.error_code == '0') & rs.next():
                    data_list.append(rs.get_row_data())

                print(f"baostock è¿”å›æ•°æ®è¡Œæ•°: {len(data_list)}")
                if len(data_list) > 0 and len(data_list) <= 3:
                    print(f"è°ƒè¯•: æ•°æ®æ ·ä¾‹: {data_list[0]}")

                if not data_list:
                    print("æœªè·å–åˆ°ä»»ä½•æ•°æ®")
                    return None, None

                # è½¬æ¢ä¸ºDataFrame
                columns = ['date', 'time', 'open', 'high', 'low', 'close', 'volume', 'amount']
                df = pd.DataFrame(data_list, columns=columns)

                # å¤„ç†æ—¶é—´æˆ³ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼‰
                def parse_timestamp_vectorized(date_series, time_series):
                    """å‘é‡åŒ–è§£ææ—¶é—´æˆ³"""
                    timestamps = []
                    for date_val, time_val in zip(date_series, time_series):
                        try:
                            time_str = str(time_val).strip()
                            date_str = str(date_val).strip()

                            # å¤„ç† baostock çš„ä¸åŒæ—¶é—´æ ¼å¼
                            if len(time_str) >= 14 and time_str.isdigit():
                                # YYYYMMDDHHMMSS æ ¼å¼ (å¦‚: 20250512093500000)
                                try:
                                    year = time_str[:4]
                                    month = time_str[4:6]
                                    day = time_str[6:8]
                                    hour = time_str[8:10]
                                    minute = time_str[10:12]
                                    second = time_str[12:14]
                                    datetime_str = f"{year}-{month}-{day} {hour}:{minute}:{second}"
                                    timestamps.append(pd.to_datetime(datetime_str))
                                except Exception:
                                    timestamps.append(pd.to_datetime(date_str))
                            else:
                                # å°è¯•å…¶ä»–æ ¼å¼
                                try:
                                    combined_str = f"{date_str} {time_str}"
                                    timestamps.append(pd.to_datetime(combined_str))
                                except Exception:
                                    timestamps.append(pd.to_datetime(date_str))
                        except Exception:
                            try:
                                timestamps.append(pd.to_datetime(date_val))
                            except:
                                timestamps.append(pd.NaT)
                    return pd.Series(timestamps)

                df['timestamps'] = parse_timestamp_vectorized(df['date'], df['time'])
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ— æ•ˆæ—¶é—´æˆ³
                invalid_timestamps = df['timestamps'].isna().sum()
                if invalid_timestamps > 0:
                    print(f"âš ï¸ è­¦å‘Š: æœ‰ {invalid_timestamps} ä¸ªæ— æ•ˆæ—¶é—´æˆ³ï¼Œå°†ä½¿ç”¨æ—¥æœŸå­—æ®µ")
                    # ç”¨æ—¥æœŸå­—æ®µå¡«å……æ— æ•ˆæ—¶é—´æˆ³
                    invalid_mask = df['timestamps'].isna()
                    df.loc[invalid_mask, 'timestamps'] = pd.to_datetime(df.loc[invalid_mask, 'date'])

                # é€‰æ‹©å¹¶é‡å‘½ååˆ—
                df = df[['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']].copy()

                # æ•°æ®ç±»å‹è½¬æ¢
                numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'amount']
                for col in numeric_columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')

                # åˆ é™¤æ— æ•ˆæ•°æ®
                df = df.dropna()

                print(f"æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
                return df, symbol

            except Exception as inner_e:
                print(f"è·å–æ•°æ®æ—¶å‡ºé”™: {inner_e}")
                return None, None

        except ImportError:
            print("é”™è¯¯: è¯·å…ˆå®‰è£…baostock: pip install baostock")
            print("å¹¶æ³¨å†Œè´¦å·è·å–token: https://www.baostock.com/")
            return None, None
        except Exception as e:
            print(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
            return None, None

    def save_data(self, df, symbol, period, stock_name, latest_timestamp):
        """
        ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶å’Œå…ƒæ•°æ®åˆ°JSONæ–‡ä»¶
        
        Args:
            df (pd.DataFrame): è‚¡ç¥¨æ•°æ®
            symbol (str): è‚¡ç¥¨ä»£ç 
            period (str): æ—¶é—´å‘¨æœŸ
            stock_name (str): è‚¡ç¥¨åç§°
            latest_timestamp (pd.Timestamp): æœ€æ–°æ•°æ®çš„æ—¶é—´æˆ³
            
        Returns:
            tuple: (ä¿å­˜çš„CSVæ–‡ä»¶è·¯å¾„, å…ƒæ•°æ®)
        """
        if df is None or df.empty:
            print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return None, None
        
        # 1. åˆ›å»ºä»¥è‚¡ç¥¨ä»£ç å‘½åçš„æ–‡ä»¶å¤¹
        stock_dir = os.path.join(self.data_dir, symbol)
        os.makedirs(stock_dir, exist_ok=True)
        
        # 2. ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{symbol}_{period}_{timestamp}.csv"
        filepath = os.path.join(stock_dir, filename)
        
        df.to_csv(filepath, index=False)
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        
        # 3. å‡†å¤‡å¹¶ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'symbol': symbol,
            'stock_name': stock_name,
            'latest_timestamp': latest_timestamp.strftime('%Y-%m-%d %H:%M:%S'),
            'data_points': len(df),
            'period': period,
            'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'data_file': filename
        }
        meta_filepath = os.path.join(stock_dir, 'metadata.json')
        with open(meta_filepath, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {meta_filepath}")
        
        return filepath, metadata
    
    def get_stock_data(self, symbol, source='baostock', start_date=None, end_date=None,
                       period='5', save=True, force_refetch=False,
                       min_fresh_days=None, fallback_days=365):
        """
        è·å–è‚¡ç¥¨æ•°æ®ï¼Œä¼˜å…ˆä»æœ¬åœ°ç¼“å­˜åŠ è½½ã€‚
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç 
            source (str): æ•°æ®æºï¼Œ'baostock'(é»˜è®¤), 'akshare', 'yfinance', 'tushare', 'jqdatasdk'
            start_date (str): å¼€å§‹æ—¥æœŸ
            end_date (str): ç»“æŸæ—¥æœŸ
            period (str): æ—¶é—´å‘¨æœŸ
            save (bool): æ˜¯å¦ä¿å­˜æ•°æ®
            force_refetch (bool): æ˜¯å¦å¼ºåˆ¶é‡æ–°ä»ç½‘ç»œè·å–æ•°æ®ï¼Œå¿½ç•¥ç¼“å­˜ã€‚
            min_fresh_days (int|None): å…è®¸çš„æœ€å¤§æ•°æ®æ»åå¤©æ•°ï¼Œè¶…è¿‡åè‡ªåŠ¨åˆ·æ–°
            fallback_days (int|None): å½“æ•°æ®è¿‡æ—§æ—¶é‡æ–°æ‹‰å–çš„æ—¶é—´è·¨åº¦ï¼ˆå•ä½ï¼šå¤©ï¼‰
        
        Returns:
            tuple: (æ•°æ®DataFrame, æ–‡ä»¶è·¯å¾„, å…ƒæ•°æ®)
        """
        print(f"å¼€å§‹è·å–è‚¡ç¥¨ {symbol} çš„æ•°æ®...")
        
        stock_dir = os.path.join(self.data_dir, symbol)
        meta_filepath = os.path.join(stock_dir, 'metadata.json')

        refresh_needed = force_refetch
        stale_refresh_triggered = False
        cached_df = None
        cached_metadata = None
        query_start_date = start_date
        query_end_date = end_date

        # --- æ–°å¢ï¼šæ•°æ®ç¼“å­˜åŠ è½½é€»è¾‘ ---
        if not refresh_needed and os.path.exists(meta_filepath):
            print(f"ğŸ” æ‰¾åˆ°è‚¡ç¥¨ {symbol} çš„ç¼“å­˜å…ƒæ•°æ®ï¼Œå°è¯•åŠ è½½...")
            try:
                with open(meta_filepath, 'r', encoding='utf-8') as f:
                    cached_metadata = json.load(f)
                
                # éªŒè¯å‘¨æœŸæ˜¯å¦åŒ¹é…
                cached_period = cached_metadata.get('period')
                requested_period_label = self._format_period_label(period)
                
                if cached_period != requested_period_label:
                    print(f"âš ï¸ ç¼“å­˜æ•°æ®å‘¨æœŸ ({cached_period}) ä¸è¯·æ±‚å‘¨æœŸ ({requested_period_label}) ä¸åŒ¹é…ï¼Œå°†é‡æ–°è·å–ã€‚")
                    refresh_needed = True
                else:
                    data_filename = cached_metadata.get('data_file')
                    if data_filename:
                        filepath = os.path.join(stock_dir, data_filename)
                        if os.path.exists(filepath):
                            print(f"âœ… æˆåŠŸåŠ è½½ç¼“å­˜æ•°æ®: {filepath}")
                            cached_df = pd.read_csv(filepath)
                            # åŠ è½½åï¼Œç¡®ä¿timestampsåˆ—æ˜¯datetimeå¯¹è±¡
                            cached_df['timestamps'] = pd.to_datetime(cached_df['timestamps'])

                            if min_fresh_days is not None:
                                freshness_threshold = datetime.now() - timedelta(days=min_fresh_days)
                                latest_timestamp = cached_df['timestamps'].max()
                                if pd.isna(latest_timestamp) or latest_timestamp < freshness_threshold:
                                    refresh_needed = True
                                    stale_refresh_triggered = True
                                    if fallback_days is not None:
                                        query_start_date = (datetime.now() - timedelta(days=fallback_days)).strftime('%Y-%m-%d')
                                        query_end_date = datetime.now().strftime('%Y-%m-%d')
                                    print(
                                        f"âš ï¸ ç¼“å­˜æ•°æ®æœ€æ–°æ—¶é—´ {latest_timestamp} æ—©äº {min_fresh_days} å¤©å‰ï¼Œ"
                                        "å°†é‡æ–°è·å–æ•°æ®ã€‚"
                                    )
                                else:
                                    print("âœ… ç¼“å­˜æ•°æ®æ»¡è¶³æ–°é²œåº¦è¦æ±‚ã€‚")
                            
                            if not refresh_needed:
                                return cached_df, filepath, cached_metadata
                        else:
                            print("âš ï¸ ç¼“å­˜æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå‡†å¤‡é‡æ–°è·å–ã€‚")
                    else:
                        print("âš ï¸ ç¼“å­˜å…ƒæ•°æ®ä¸å®Œæ•´æˆ–æ•°æ®æ–‡ä»¶ä¸¢å¤±ã€‚")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥: {e}")

        if refresh_needed:
            print("â„¹ï¸ å°†ä»ç½‘ç»œè·å–æœ€æ–°æ•°æ®...")
            if stale_refresh_triggered and fallback_days is not None:
                query_start_date = (datetime.now() - timedelta(days=fallback_days)).strftime('%Y-%m-%d')
                query_end_date = datetime.now().strftime('%Y-%m-%d')
                print(f"   è§¦å‘è¿‡æœŸåˆ·æ–°ï¼Œæ—¶é—´èŒƒå›´è®¾ç½®ä¸º: {query_start_date} è‡³ {query_end_date}")
            elif fallback_days is not None and query_start_date is None:
                query_start_date = (datetime.now() - timedelta(days=fallback_days)).strftime('%Y-%m-%d')
                query_end_date = datetime.now().strftime('%Y-%m-%d')
                print(f"   ä½¿ç”¨ fallback_days={fallback_days}ï¼Œæ—¶é—´èŒƒå›´è®¾ç½®ä¸º: {query_start_date} è‡³ {query_end_date}")
            elif query_end_date is None:
                query_end_date = datetime.now().strftime('%Y-%m-%d')
        else:
            print("â„¹ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆç¼“å­˜ï¼Œå°†ä»ç½‘ç»œè·å–æ–°æ•°æ®ã€‚")
            if fallback_days is not None and query_start_date is None:
                query_start_date = (datetime.now() - timedelta(days=fallback_days)).strftime('%Y-%m-%d')
                print(f"   ä½¿ç”¨ fallback_days={fallback_days}ï¼Œæ—¶é—´èŒƒå›´è®¾ç½®ä¸º: {query_start_date} è‡³ {query_end_date}")
            if query_end_date is None:
                query_end_date = datetime.now().strftime('%Y-%m-%d')
        
        print(f"ğŸ“… æœ€ç»ˆæŸ¥è¯¢æ—¶é—´èŒƒå›´: {query_start_date} è‡³ {query_end_date}")
        
        # æ ¹æ®æ•°æ®æºè·å–æ•°æ®ï¼ˆä½¿ç”¨å­—å…¸æ˜ å°„ä¼˜åŒ–ï¼‰
        source_map = {
            'akshare': self.fetch_from_akshare,
            'yfinance': self.fetch_from_yfinance,
            'baostock': self.fetch_from_baostock,
            'tushare': getattr(self, 'fetch_from_tushare', None),
            'jqdatasdk': getattr(self, 'fetch_from_jqdatasdk', None)
        }
        
        source_lower = source.lower()
        fetch_func = source_map.get(source_lower)
        
        if fetch_func is None:
            print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
            print("æ”¯æŒçš„æ•°æ®æº: akshare, yfinance, baostock, tushare, jqdatasdk")
            return None, None, None
        
        try:
            df, stock_name = fetch_func(symbol, query_start_date, query_end_date, period)
        except Exception as e:
            print(f"âŒ ä» {source} è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
            return None, None, None
        
        if df is None or df.empty:
            print("è·å–æ•°æ®å¤±è´¥")
            return None, None, None

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ®µæ‹‰å–æ›´å¤šæ•°æ®
        if fallback_days is not None and fallback_days > 30:  # åªæœ‰å½“è¯·æ±‚å¤©æ•°è¾ƒå¤šæ—¶æ‰è€ƒè™‘åˆ†æ®µæ‹‰å–
            # è®¡ç®—é¢„æœŸçš„æ•°æ®é‡
            expected_rows = self._estimate_expected_rows(fallback_days, period)
            actual_rows = len(df)

            # å¦‚æœå®é™…æ•°æ®é‡è¿œå°äºé¢„æœŸï¼Œå°è¯•åˆ†æ®µæ‹‰å–
            if actual_rows < expected_rows * DATA_AMOUNT_CHECK_RATIO:
                print(f"âš ï¸ æ•°æ®é‡ä¸è¶³: å®é™…{actual_rows}æ¡ï¼Œé¢„æœŸçº¦{expected_rows}æ¡ï¼Œå°è¯•åˆ†æ®µæ‹‰å–...")
                print(f"   æ•°æ®æ—¶é—´èŒƒå›´: {df['timestamps'].min()} è‡³ {df['timestamps'].max()}")
                df = self._fetch_with_chunks(symbol, source, start_date, end_date, period, fallback_days)
                if df is None or df.empty:
                    print("âŒ åˆ†æ®µæ‹‰å–å¤±è´¥")
                    return None, None, None
                else:
                    print(f"âœ… åˆ†æ®µæ‹‰å–æˆåŠŸ: ä»{actual_rows}æ¡å¢åŠ åˆ°{len(df)}æ¡")
                    print(f"   æ–°æ•°æ®æ—¶é—´èŒƒå›´: {df['timestamps'].min()} è‡³ {df['timestamps'].max()}")
            else:
                print(f"âœ… æ•°æ®é‡æ­£å¸¸: {actual_rows}æ¡ (é¢„æœŸçº¦{expected_rows}æ¡)")

        # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœç”¨æˆ·è¦æ±‚è¾ƒé•¿å†å²ä½†æ•°æ®ä»ç„¶å¾ˆå°‘ï¼Œå¼ºåˆ¶åˆ†æ®µæ‹‰å–
        if fallback_days is not None and fallback_days >= 90 and len(df) < MIN_DATA_FOR_CHUNK:
            print(f"å¼ºåˆ¶åˆ†æ®µæ‹‰å–: è¯·æ±‚{fallback_days}å¤©æ•°æ®ä½†åªæœ‰{len(df)}æ¡ï¼Œå°è¯•è·å–æ›´é•¿å†å²...")
            df = self._fetch_with_chunks(symbol, source, start_date, end_date, period, fallback_days)
            if df is None or df.empty:
                print("å¼ºåˆ¶åˆ†æ®µæ‹‰å–å¤±è´¥")
                return None, None, None

        # ä¿å­˜æ•°æ®
        filepath, metadata = None, None
        if save:
            period_label = self._format_period_label(period)
            latest_timestamp = df['timestamps'].iloc[-1]
            filepath, metadata = self.save_data(df, symbol, period_label, stock_name, latest_timestamp)

        return df, filepath, metadata

    def _estimate_expected_rows(self, days, period):
        """ä¼°ç®—æŒ‡å®šå¤©æ•°å’Œå‘¨æœŸçš„é¢„æœŸæ•°æ®è¡Œæ•°"""
        if period == 'D':
            # æ—¥çº¿æ•°æ®ï¼šæ¯ä¸ªäº¤æ˜“æ—¥1æ¡
            return max(int(days * TRADING_DAYS_RATIO), int(days * 0.5))

        try:
            minutes_per_period = int(period)
            rows_per_day = TRADING_MINUTES_PER_DAY // minutes_per_period
            expected_rows = days * rows_per_day * TRADING_DAYS_RATIO
            return int(expected_rows)
        except ValueError:
            # å¦‚æœæ— æ³•è§£æå‘¨æœŸï¼Œè¿”å›ä¿å®ˆä¼°è®¡
            return days * 50  # å‡è®¾æ¯å¤©çº¦50æ¡æ•°æ®

    def _fetch_with_chunks(self, symbol, source, start_date, end_date, period, required_days):
        """
        åˆ†æ®µæ‹‰å–æ•°æ®ä»¥è·å–æ›´å¤šå†å²æ•°æ®

        Args:
            symbol (str): è‚¡ç¥¨ä»£ç 
            source (str): æ•°æ®æº
            start_date (str): å¼€å§‹æ—¥æœŸ
            end_date (str): ç»“æŸæ—¥æœŸ
            period (str): å‘¨æœŸ
            required_days (int): éœ€è¦æ‹‰å–çš„å¤©æ•°

        Returns:
            pd.DataFrame: åˆå¹¶åçš„æ•°æ®
        """
        # æ ¹æ®æ•°æ®æºè°ƒæ•´åˆ†æ®µç­–ç•¥
        source_lower = source.lower()
        chunk_days = CHUNK_DAYS_MAP.get(source_lower, CHUNK_DAYS_MAP['default'])
        max_attempts = MAX_ATTEMPTS_MAP.get(source_lower, MAX_ATTEMPTS_MAP['default'])

        # è®¡ç®—ç»“æŸæ—¥æœŸï¼ˆé€šå¸¸æ˜¯ä»Šå¤©ï¼‰
        end_dt = datetime.now() if end_date is None else pd.to_datetime(end_date)

        print(f"åˆ†æ®µæ‹‰å–æ¨¡å¼: ä»æœ€è¿‘æ—¶é—´å¼€å§‹å‘å‰æ‹‰å–ï¼Œæ¯æ®µ {chunk_days} å¤©ï¼Œæœ€å¤š {max_attempts} æ®µ")

        frames = []
        current_end = end_dt
        attempts = 0
        consecutive_empty = 0  # è¿ç»­ç©ºæ•°æ®æ®µè®¡æ•°

        while attempts < max_attempts and consecutive_empty < MAX_CONSECUTIVE_EMPTY:
            # ä»æœ€è¿‘æ—¶é—´å¼€å§‹å‘å‰æ‹‰å–
            current_start = current_end - timedelta(days=chunk_days - 1)
            # ç¡®ä¿ä¸æ—©äº start_dateï¼ˆå¦‚æœæŒ‡å®šäº†çš„è¯ï¼‰
            if start_date and pd.to_datetime(start_date) > current_start:
                current_start = pd.to_datetime(start_date)

            start_str = current_start.strftime('%Y-%m-%d')
            end_str = current_end.strftime('%Y-%m-%d')

            print(f"  æ­£åœ¨æ‹‰å–æ®µ {attempts + 1}: {start_str} è‡³ {end_str}")

            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•ï¼ˆä½¿ç”¨å­—å…¸æ˜ å°„ä¼˜åŒ–ï¼‰
            source_map = {
                'akshare': self.fetch_from_akshare,
                'yfinance': self.fetch_from_yfinance,
                'baostock': self.fetch_from_baostock
            }
            
            fetch_func = source_map.get(source.lower())
            if fetch_func is None:
                print(f"åˆ†æ®µæ‹‰å–ä¸æ”¯æŒæ•°æ®æº: {source}")
                break
            
            try:
                chunk_df, _ = fetch_func(symbol, start_str, end_str, period)

                if chunk_df is not None and not chunk_df.empty:
                    frames.append(chunk_df)
                    print(f"    è·å–åˆ° {len(chunk_df)} æ¡æ•°æ®")
                    consecutive_empty = 0  # é‡ç½®è¿ç»­ç©ºæ•°æ®è®¡æ•°
                else:
                    print(f"    è¯¥æ®µæ— æ•°æ®")
                    consecutive_empty += 1

            except Exception as e:
                print(f"    æ‹‰å–å¤±è´¥: {e}")
                consecutive_empty += 1

            # å‘å‰ç§»åŠ¨åˆ°ä¸‹ä¸€æ®µ
            current_end = current_start - timedelta(days=1)
            attempts += 1

            # å¦‚æœå·²ç»è¾¾åˆ°æœ€æ—©çš„å¯ç”¨æ•°æ®ï¼Œå°±åœæ­¢
            if start_date and current_end < pd.to_datetime(start_date):
                print("å·²è¾¾åˆ°æŒ‡å®šçš„æœ€æ—©æ—¥æœŸï¼Œåœæ­¢æ‹‰å–")
                break

            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            delay = REQUEST_DELAY_MAP.get(source.lower(), REQUEST_DELAY_MAP['default'])
            time.sleep(delay)

        if frames:
            # åˆå¹¶æ‰€æœ‰æ•°æ®æ®µ
            combined_df = pd.concat(frames, ignore_index=True)

            # å»é‡å¹¶æ’åº
            combined_df = combined_df.drop_duplicates(subset=['timestamps']).sort_values('timestamps').reset_index(drop=True)

            print(f"åˆ†æ®µæ‹‰å–å®Œæˆï¼Œå…±è·å– {len(combined_df)} æ¡æ•°æ®ï¼Œè¦†ç›–æ—¶é—´: {combined_df['timestamps'].min()} è‡³ {combined_df['timestamps'].max()}")
            return combined_df
        else:
            print("åˆ†æ®µæ‹‰å–å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
            return None

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Kronos è‚¡ç¥¨æ•°æ®è·å–å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # è·å–Aè‚¡æ•°æ® (é»˜è®¤)
  python stock_data_fetcher.py --symbol 000001

  # è·å–ç¾è‚¡æ•°æ®
  python stock_data_fetcher.py --symbol AAPL --source yfinance --period 5m

  # ä½¿ç”¨baostockè·å–Aè‚¡æ•°æ® (æ¨èï¼Œç¨³å®šå¯é )
  python stock_data_fetcher.py --symbol 300708 --source baostock --days 180

  # æŒ‡å®šæ—¶é—´èŒƒå›´å’Œæ•°æ®é‡
  python stock_data_fetcher.py --symbol 000001 --days 365 --period 5

  # å¼ºåˆ¶é‡æ–°è·å–æ•°æ®
  python stock_data_fetcher.py --symbol 000001 --force

æ³¨æ„:
  ä½¿ç”¨ baostock å‰éœ€è¦å…ˆè¿è¡Œ: python -c "import baostock as bs; bs.login()"
  å¹¶æ³¨å†Œè´¦å·è·å–token: https://www.baostock.com/
        """
    )

    parser.add_argument(
        "--symbol", "-s",
        required=True,
        help="è‚¡ç¥¨ä»£ç  (Aè‚¡: 000001, ç¾è‚¡: AAPL)"
    )

    parser.add_argument(
        "--source",
        choices=["akshare", "yfinance", "baostock", "tushare", "jqdatasdk"],
        default="baostock",
        help="æ•°æ®æº (é»˜è®¤: baostockï¼Œæ¨èç”¨äºAè‚¡)"
    )

    parser.add_argument(
        "--period", "-p",
        default="5",
        help="æ—¶é—´å‘¨æœŸ (åˆ†é’Ÿçº¿: 1,5,15,30,60; æ—¥çº¿: D; yfinanceç”¨: 1m,5mç­‰)"
    )

    parser.add_argument(
        "--days", "-d",
        type=int,
        default=30,
        help="è·å–æœ€è¿‘ N å¤©çš„å†å²æ•°æ® (é»˜è®¤: 30)"
    )

    parser.add_argument(
        "--force", "-f",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°è·å–æ•°æ®ï¼Œå¿½ç•¥ç¼“å­˜"
    )

    parser.add_argument(
        "--start-date",
        help="æŒ‡å®šå¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)"
    )

    parser.add_argument(
        "--end-date",
        help="æŒ‡å®šç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)"
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå‚æ•°"""
    args = parse_arguments()

    # åˆ›å»ºæ•°æ®è·å–å™¨
    fetcher = StockDataFetcher()

    print("=" * 60)
    print(f"ğŸ¯ è·å–è‚¡ç¥¨æ•°æ®: {args.symbol} ({args.source})")
    print("=" * 60)

    # è®¡ç®—æ—¶é—´èŒƒå›´
    if args.start_date and args.end_date:
        start_date = args.start_date
        end_date = args.end_date
    else:
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=args.days)).strftime('%Y-%m-%d')

    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
    print(f"â° æ—¶é—´å‘¨æœŸ: {args.period}")
    print(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°: {'æ˜¯' if args.force else 'å¦'}")
    print("=" * 60)

    # è·å–æ•°æ®
    df, filepath, metadata = fetcher.get_stock_data(
        symbol=args.symbol,
        source=args.source,
        start_date=start_date,
        end_date=end_date,
        period=args.period,
        save=True,
        force_refetch=args.force,
        min_fresh_days=7 if not args.force else None,  # éå¼ºåˆ¶åˆ·æ–°æ—¶æ£€æŸ¥æ–°é²œåº¦
        fallback_days=args.days
    )

    if df is not None and filepath is not None:
        print("\n" + "=" * 60)
        print("âœ… æ•°æ®è·å–æˆåŠŸ!")
        print("=" * 60)
        print(f"ğŸ“Š æ•°æ®æ¡æ•°: {len(df)}")
        print(f"ğŸ’¾ ä¿å­˜è·¯å¾„: {filepath}")
        print(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {df['timestamps'].min()} è‡³ {df['timestamps'].max()}")

        print(f"\nğŸ“‹ æ•°æ®é¢„è§ˆ:")
        print(df.head())

        if metadata:
            print(f"\nğŸ“„ å…ƒæ•°æ®:")
            print(json.dumps(metadata, indent=2, ensure_ascii=False))
    else:
        print("\nâŒ æ•°æ®è·å–å¤±è´¥!")
        return 1

    return 0


# å…¼å®¹æ—§ç‰ˆç›´æ¥è¿è¡Œ
def demo():
    """æ¼”ç¤ºå‡½æ•° - ä¿æŒå‘åå…¼å®¹"""
    print("è¿è¡Œæ¼”ç¤ºæ¨¡å¼...")

    # åˆ›å»ºæ•°æ®è·å–å™¨
    fetcher = StockDataFetcher()

    print("=" * 50)
    print("è·å–Aè‚¡æ•°æ®æ¼”ç¤º")
    print("=" * 50)

    # è·å–å¹³å®‰é“¶è¡Œ5åˆ†é’Ÿæ•°æ®
    df_a, filepath_a, metadata_a = fetcher.get_stock_data(
        symbol='000001',  # å¹³å®‰é“¶è¡Œ
        source='akshare',
        start_date='2024-01-01',
        end_date='2024-01-31',
        period='5',
        save=True
    )

    if df_a is not None:
        print(f"æ•°æ®é¢„è§ˆ:")
        print(df_a.head())
        print(f"\nå…ƒæ•°æ®:")
        print(json.dumps(metadata_a, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
        if len(os.sys.argv) > 1 and os.sys.argv[1] not in ['demo', '--help', '-h']:
            # æœ‰å‚æ•°ï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼
            exit(main())
        else:
            # æ— å‚æ•°æˆ–æ˜ç¡®æŒ‡å®šdemoï¼Œè¿è¡Œæ¼”ç¤º
            demo()
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        exit(1)
    except Exception as e:
        print(f"æ‰§è¡Œå‡ºé”™: {e}")
        exit(1)
