#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨é¢„æµ‹åˆ†ææ¨¡å—
åŸºäºKronosæ¨¡å‹è¿›è¡Œè‚¡ç¥¨é¢„æµ‹å¹¶ä¿å­˜ç»“æœ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import sys
import json
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from model import Kronos, KronosTokenizer, KronosPredictor
except ImportError:
    print("é”™è¯¯: æ— æ³•å¯¼å…¥Kronosæ¨¡å‹ï¼Œè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)

class StockPredictor:
    """è‚¡ç¥¨é¢„æµ‹å™¨"""
    
    def __init__(self, device="cpu", max_context=512, results_dir="my_stock_predictor/prediction_results"):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            device (str): è®¡ç®—è®¾å¤‡ï¼Œ'cpu' æˆ– 'cuda:0'
            max_context (int): æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            results_dir (str): ç»“æœä¿å­˜ç›®å½•
        """
        self.device = device
        self.max_context = max_context
        self.results_dir = results_dir
        self.model = None
        self.tokenizer = None
        self.predictor = None
        
        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        self.ensure_results_dir()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.load_model()
    
    def ensure_results_dir(self):
        """ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
            print(f"åˆ›å»ºç»“æœç›®å½•: {self.results_dir}")
    
    def load_model(self):
        """åŠ è½½Kronosæ¨¡å‹"""
        try:
            print("æ­£åœ¨åŠ è½½Kronosæ¨¡å‹...")
            
            # åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹
            self.tokenizer = KronosTokenizer.from_pretrained("NeoQuasar/Kronos-Tokenizer-base")
            self.model = Kronos.from_pretrained("NeoQuasar/Kronos-small")
            
            # åˆ›å»ºé¢„æµ‹å™¨
            self.predictor = KronosPredictor(
                self.model, 
                self.tokenizer, 
                device=self.device, 
                max_context=self.max_context
            )
            
            print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def load_data(self, filepath):
        """
        åŠ è½½è‚¡ç¥¨æ•°æ®
        
        Args:
            filepath (str): æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ®
        """
        try:
            print(f"æ­£åœ¨åŠ è½½æ•°æ®: {filepath}")
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(filepath)
            
            # ç¡®ä¿æ—¶é—´æˆ³åˆ—å­˜åœ¨
            if 'timestamps' not in df.columns:
                print("é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸­ç¼ºå°‘timestampsåˆ—")
                return None
            
            # è½¬æ¢æ—¶é—´æˆ³æ ¼å¼
            df['timestamps'] = pd.to_datetime(df['timestamps'])
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
            required_columns = ['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                print(f"è­¦å‘Š: ç¼ºå°‘åˆ—: {missing_columns}")
                # å°è¯•ç”¨å…¶ä»–åˆ—ååŒ¹é…
                column_mapping = {
                    'Open': 'open',
                    'High': 'high',
                    'Low': 'low',
                    'Close': 'close',
                    'Volume': 'volume',
                    'Amount': 'amount'
                }
                
                for old_col, new_col in column_mapping.items():
                    if old_col in df.columns and new_col not in df.columns:
                        df[new_col] = df[old_col]
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'amount']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # åˆ é™¤æ— æ•ˆæ•°æ®
            df = df.dropna()
            
            # æŒ‰æ—¶é—´æ’åº
            df = df.sort_values('timestamps').reset_index(drop=True)
            
            print(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®")
            print(f"æ—¶é—´èŒƒå›´: {df['timestamps'].min()} åˆ° {df['timestamps'].max()}")
            
            return df
            
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None
    
    def prepare_prediction_data(self, df, lookback=400, pred_len=120):
        """
        å‡†å¤‡é¢„æµ‹æ•°æ®
        
        Args:
            df (pd.DataFrame): è‚¡ç¥¨æ•°æ®
            lookback (int): å›çœ‹çª—å£å¤§å°
            pred_len (int): é¢„æµ‹é•¿åº¦
            
        Returns:
            tuple: (è¾“å…¥æ•°æ®, è¾“å…¥æ—¶é—´æˆ³, è¾“å‡ºæ—¶é—´æˆ³)
        """
        if len(df) < lookback + pred_len:
            print(f"è­¦å‘Š: æ•°æ®é•¿åº¦({len(df)})å°äºlookback({lookback}) + pred_len({pred_len})")
            # è°ƒæ•´å‚æ•°
            lookback = min(lookback, len(df) // 2)
            pred_len = min(pred_len, len(df) - lookback)
            print(f"è°ƒæ•´å‚æ•°: lookback={lookback}, pred_len={pred_len}")
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        x_df = df.loc[:lookback-1, ['open', 'high', 'low', 'close', 'volume', 'amount']]
        x_timestamp = df.loc[:lookback-1, 'timestamps']
        y_timestamp = df.loc[lookback:lookback+pred_len-1, 'timestamps']
        
        return x_df, x_timestamp, y_timestamp
    
    def predict(self, x_df, x_timestamp, y_timestamp, pred_len, T=1.0, top_p=0.9, sample_count=1):
        """
        è¿›è¡Œé¢„æµ‹
        
        Args:
            x_df (pd.DataFrame): è¾“å…¥ç‰¹å¾
            x_timestamp (pd.Series): è¾“å…¥æ—¶é—´æˆ³
            y_timestamp (pd.Series): é¢„æµ‹æ—¶é—´æˆ³
            pred_len (int): é¢„æµ‹é•¿åº¦
            T (float): é‡‡æ ·æ¸©åº¦
            top_p (float): æ ¸é‡‡æ ·æ¦‚ç‡
            sample_count (int): é‡‡æ ·æ¬¡æ•°
            
        Returns:
            pd.DataFrame: é¢„æµ‹ç»“æœ
        """
        try:
            print("æ­£åœ¨è¿›è¡Œé¢„æµ‹...")
            pred_df = self.predictor.predict(
                df=x_df,
                x_timestamp=x_timestamp,
                y_timestamp=y_timestamp,
                pred_len=pred_len,
                T=T,
                top_p=top_p,
                sample_count=sample_count,
                verbose=True
            )
            
            print("é¢„æµ‹å®Œæˆï¼")
            return pred_df
            
        except Exception as e:
            print(f"é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def plot_prediction(self, historical_df, pred_df, symbol, is_future_forecast=False, save_plot=True):
        """
        ç»˜åˆ¶é¢„æµ‹ç»“æœ
        """
        try:
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            # å‡†å¤‡ç»˜å›¾æ•°æ®
            start_pred_time = pred_df.index.min()
            historical_plot_df = historical_df[historical_df['timestamps'] < start_pred_time].tail(400)
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8), sharex=True)
            
            # --- ä»·æ ¼å›¾ ---
            ax1.plot(historical_plot_df['timestamps'], historical_plot_df['close'], label='å†å²ä»·æ ¼', color='blue', linewidth=1.5)
            ax1.plot(pred_df.index, pred_df['close'], label='é¢„æµ‹ä»·æ ¼', color='red', linewidth=1.5, linestyle='--')
            
            # åœ¨å›æµ‹æ¨¡å¼ä¸‹ï¼Œæ·»åŠ çœŸå®ä»·æ ¼æ›²çº¿
            if not is_future_forecast:
                true_values_df = historical_df[historical_df['timestamps'].isin(pred_df.index)]
                ax1.plot(true_values_df['timestamps'], true_values_df['close'], label='çœŸå®ä»·æ ¼', color='green', linewidth=1.5, alpha=0.7)
            
            ax1.set_ylabel('ä»·æ ¼', fontsize=14)
            ax1.set_title(f'{symbol} è‚¡ç¥¨é¢„æµ‹ç»“æœ', fontsize=16)
            ax1.legend(loc='upper left', fontsize=12)
            ax1.grid(True, alpha=0.3)
            if not historical_plot_df.empty:
                ax1.axvline(historical_plot_df['timestamps'].iloc[-1], color='gray', linestyle='--', linewidth=1)
            
            # --- æˆäº¤é‡å›¾ ---
            ax2.plot(historical_plot_df['timestamps'], historical_plot_df['volume'], label='å†å²æˆäº¤é‡', color='blue', linewidth=1.5)
            ax2.plot(pred_df.index, pred_df['volume'], label='é¢„æµ‹æˆäº¤é‡', color='red', linewidth=1.5, linestyle='--')
            
            if not is_future_forecast:
                true_values_df = historical_df[historical_df['timestamps'].isin(pred_df.index)]
                ax2.plot(true_values_df['timestamps'], true_values_df['volume'], label='çœŸå®æˆäº¤é‡', color='green', linewidth=1.5, alpha=0.7)
            
            ax2.set_ylabel('æˆäº¤é‡', fontsize=14)
            ax2.set_xlabel('æ—¶é—´', fontsize=14)
            ax2.legend(loc='upper left', fontsize=12)
            ax2.grid(True, alpha=0.3)
            if not historical_plot_df.empty:
                ax2.axvline(historical_plot_df['timestamps'].iloc[-1], color='gray', linestyle='--', linewidth=1)
            
            plt.xticks(rotation=30, ha='right')
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            plot_path = None
            if save_plot:
                # --- ä¿®æ­£: åˆ›å»ºè‚¡ç¥¨ä¸“å±çš„ç»“æœå­æ–‡ä»¶å¤¹ ---
                symbol_results_dir = os.path.join(self.results_dir, symbol)
                os.makedirs(symbol_results_dir, exist_ok=True)

                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                plot_filename = f"{symbol}_prediction_chart_{timestamp}.png"
                plot_path = os.path.join(symbol_results_dir, plot_filename)
                plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                print(f"å›¾è¡¨å·²ä¿å­˜: {plot_path}")
            
            plt.show()
            
            return plot_path
            
        except Exception as e:
            print(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {e}")
            return None
    
    def save_prediction_results(self, pred_df, symbol, metadata=None):
        """
        ä¿å­˜é¢„æµ‹ç»“æœ
        
        Args:
            pred_df (pd.DataFrame): é¢„æµ‹ç»“æœ
            symbol (str): è‚¡ç¥¨ä»£ç 
            metadata (dict): å…ƒæ•°æ®
            
        Returns:
            str: ç»“æœæ–‡ä»¶è·¯å¾„
        """
        try:
            # --- ä¿®æ­£: åˆ›å»ºè‚¡ç¥¨ä¸“å±çš„ç»“æœå­æ–‡ä»¶å¤¹ ---
            symbol_results_dir = os.path.join(self.results_dir, symbol)
            os.makedirs(symbol_results_dir, exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜é¢„æµ‹æ•°æ®
            csv_filename = f"{symbol}_prediction_data_{timestamp}.csv"
            csv_path = os.path.join(symbol_results_dir, csv_filename)
            
            # å°†ç´¢å¼•é‡ç½®ä¸ºåˆ—ï¼Œå¹¶ç¡®ä¿åˆ—åä¸º'timestamps'
            save_df = pred_df.reset_index()
            if 'index' in save_df.columns:
                save_df = save_df.rename(columns={'index': 'timestamps'})
            
            save_df.to_csv(csv_path, index=False)
            
            # ä¿å­˜å…ƒæ•°æ®
            if metadata is None:
                metadata = {}
            
            metadata.update({
                'symbol': symbol,
                'prediction_time': timestamp,
                'data_points': len(pred_df),
                'columns': list(pred_df.columns)
            })
            
            json_filename = f"{symbol}_metadata_{timestamp}.json"
            json_path = os.path.join(symbol_results_dir, json_filename)
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ '{symbol_results_dir}' ç›®å½•:")
            print(f"  - æ•°æ®æ–‡ä»¶: {os.path.basename(csv_path)}")
            print(f"  - å…ƒæ•°æ®æ–‡ä»¶: {os.path.basename(json_path)}")
            
            return csv_path
            
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return None
    
    def analyze_prediction(self, historical_df, pred_df, symbol, is_future_forecast):
        """
        åˆ†æé¢„æµ‹ç»“æœ
        """
        try:
            # è·å–å†å²æ•°æ®çš„æœ€åä¸€ä¸ªç‚¹ç”¨äºæ¯”è¾ƒ
            last_historical_point = historical_df.iloc[-1]
            last_close = last_historical_point['close']
            
            # é¢„æµ‹æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
            pred_close_stats = {
                'mean': pred_df['close'].mean(),
                'std': pred_df['close'].std(),
                'min': pred_df['close'].min(),
                'max': pred_df['close'].max(),
                'trend': 'ä¸Šæ¶¨' if pred_df['close'].iloc[-1] > pred_df['close'].iloc[0] else 'ä¸‹è·Œ'
            }
            
            pred_volume_stats = {
                'mean': pred_df['volume'].mean(),
                'std': pred_df['volume'].std(),
                'min': pred_df['volume'].min(),
                'max': pred_df['volume'].max()
            }
            
            # ä»·æ ¼å˜åŒ–åˆ†æ
            # å¦‚æœæ˜¯æœªæ¥é¢„æµ‹ï¼Œä¸æœ€åä¸€ä¸ªå†å²ç‚¹æ¯”è¾ƒ
            # å¦‚æœæ˜¯å›æµ‹ï¼Œä¸é¢„æµ‹å¼€å§‹å‰çš„é‚£ä¸ªç‚¹æ¯”è¾ƒ
            if is_future_forecast:
                comparison_close = last_close
            else:
                # æ‰¾åˆ°é¢„æµ‹å¼€å§‹å‰çš„æœ€åä¸€ä¸ªç‚¹
                comparison_point = historical_df[historical_df['timestamps'] < pred_df.index.min()]
                if not comparison_point.empty:
                    comparison_close = comparison_point.iloc[-1]['close']
                else:
                    comparison_close = last_close # Fallback

            price_change = pred_df['close'].iloc[-1] - comparison_close
            price_change_pct = (price_change / comparison_close) * 100 if comparison_close != 0 else 0
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            analysis = {
                'symbol': symbol,
                'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'historical_last_close': last_close,
                'historical_last_volume': last_historical_point['volume'], # ä½¿ç”¨æœ€åä¸€ä¸ªå†å²ç‚¹çš„æˆäº¤é‡
                'prediction_periods': len(pred_df),
                'price_analysis': {
                    'predicted_last_close': pred_df['close'].iloc[-1],
                    'price_change': price_change,
                    'price_change_percentage': price_change_pct,
                    'trend': pred_close_stats['trend'],
                    'volatility': pred_close_stats['std']
                },
                'volume_analysis': {
                    'predicted_avg_volume': pred_volume_stats['mean'],
                    'volume_trend': 'å¢åŠ ' if pred_volume_stats['mean'] > last_historical_point['volume'] else 'å‡å°‘'
                },
                'statistics': {
                    'close_stats': pred_close_stats,
                    'volume_stats': pred_volume_stats
                }
            }
            
            # æ‰“å°åˆ†æç»“æœ
            print("\n" + "="*60)
            print(f"ğŸ“Š {symbol} é¢„æµ‹åˆ†ææŠ¥å‘Š")
            print("="*60)
            print(f"ğŸ“ˆ ä»·æ ¼è¶‹åŠ¿: {analysis['price_analysis']['trend']}")
            print(f"ğŸ’° é¢„æµ‹ä»·æ ¼å˜åŒ–: {price_change:.4f} ({price_change_pct:.2f}%)")
            print(f"ğŸ“Š ä»·æ ¼æ³¢åŠ¨æ€§: {pred_close_stats['std']:.4f}")
            print(f"ğŸ“ˆ æˆäº¤é‡è¶‹åŠ¿: {analysis['volume_analysis']['volume_trend']}")
            print(f"ğŸ“Š é¢„æµ‹æ•°æ®ç‚¹: {len(pred_df)}")
            print("="*60)
            
            return analysis
            
        except Exception as e:
            print(f"åˆ†æé¢„æµ‹ç»“æœå¤±è´¥: {e}")
            return None
    
    def run_prediction_pipeline(self, historical_df, x_df, x_timestamp, y_timestamp, 
                               is_future_forecast, symbol, pred_len,
                               T=1.0, top_p=0.9, sample_count=1):
        """
        è¿è¡Œå®Œæ•´çš„é¢„æµ‹æµç¨‹
        """
        print(f"ğŸš€ å¼€å§‹ {symbol} çš„é¢„æµ‹æµç¨‹...")
        
        # --- æ ¸å¿ƒä¿®æ­£: ç¡®ä¿ y_timestamp å§‹ç»ˆæ˜¯ Series ---
        # åŸå§‹æ¨¡å‹éœ€è¦ Series ç±»å‹çš„æ—¶é—´æˆ³è¾“å…¥
        if isinstance(y_timestamp, pd.DatetimeIndex):
            y_timestamp_series = pd.Series(y_timestamp, index=y_timestamp)
        else:
            y_timestamp_series = y_timestamp

        # 1. è¿›è¡Œé¢„æµ‹
        pred_df = self.predict(x_df, x_timestamp, y_timestamp_series, pred_len, T, top_p, sample_count)
        if pred_df is None:
            return None
        
        # 2. ç¡®ä¿ pred_df çš„ç´¢å¼•æ˜¯ DatetimeIndex
        pred_df.index = pd.to_datetime(pred_df.index)
        
        # 3. åˆ†æé¢„æµ‹ç»“æœ
        analysis = self.analyze_prediction(historical_df, pred_df, symbol, is_future_forecast)
        
        # 4. ç»˜åˆ¶å›¾è¡¨
        plot_path = self.plot_prediction(historical_df, pred_df, symbol, is_future_forecast)
        
        # 5. ä¿å­˜ç»“æœ
        metadata = {
            'analysis': analysis,
            'plot_path': plot_path,
            'parameters': {
                'pred_len': pred_len,
                'T': T,
                'top_p': top_p,
                'sample_count': sample_count,
                'is_future_forecast': is_future_forecast
            }
        }
        
        csv_path = self.save_prediction_results(pred_df, symbol, metadata)
        
        # 6. è¿”å›å®Œæ•´ç»“æœ
        results = {
            'symbol': symbol,
            'prediction': pred_df,
            'analysis': analysis,
            'files': {
                'csv_path': csv_path,
                'plot_path': plot_path
            },
            'metadata': metadata
        }
        
        print(f"âœ… {symbol} é¢„æµ‹æµç¨‹å®Œæˆï¼")
        return results

def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = StockPredictor(device="cpu")
    
    # ç¤ºä¾‹ï¼šä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œé¢„æµ‹
    print("="*60)
    print("ç¤ºä¾‹ï¼šä½¿ç”¨Kronosç¤ºä¾‹æ•°æ®è¿›è¡Œé¢„æµ‹")
    print("="*60)
    
    # ä½¿ç”¨é¡¹ç›®ä¸­çš„ç¤ºä¾‹æ•°æ®
    example_data_path = os.path.join("examples", "data", "XSHG_5min_600977.csv")
    
    if os.path.exists(example_data_path):
        # åŠ è½½æ•°æ®
        df = predictor.load_data(example_data_path)
        if df is None:
            print("æ— æ³•åŠ è½½ç¤ºä¾‹æ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
            return

        # å‡†å¤‡é¢„æµ‹æ•°æ®
        lookback = 400
        pred_len = 120
        x_df, x_timestamp, y_timestamp = predictor.prepare_prediction_data(df, lookback, pred_len)

        # è¿è¡Œé¢„æµ‹æµç¨‹
        results = predictor.run_prediction_pipeline(
            historical_df=df, # ä¼ å…¥å®Œæ•´çš„dfç”¨äºç»˜å›¾å’Œåˆ†æ
            x_df=x_df,
            x_timestamp=x_timestamp,
            y_timestamp=y_timestamp,
            is_future_forecast=False, # ç¤ºä¾‹æ•°æ®æ˜¯å†å²æ•°æ®ï¼Œä¸æ˜¯æœªæ¥é¢„æµ‹
            symbol="600977",
            pred_len=pred_len,
            T=1.0,
            top_p=0.9,
            sample_count=1
        )
        
        if results:
            print("\nğŸ‰ é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°prediction_resultsç›®å½•")
    else:
        print(f"ç¤ºä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {example_data_path}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®è·å–æ¨¡å—è·å–è‚¡ç¥¨æ•°æ®")

if __name__ == "__main__":
    main()
