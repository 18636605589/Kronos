#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨é¢„æµ‹åˆ†ææ¨¡å—
åŸºäºKronosæ¨¡å‹è¿›è¡Œè‚¡ç¥¨é¢„æµ‹å¹¶ä¿å­˜ç»“æœ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import sys
import json
import argparse
from datetime import datetime, timedelta
import torch
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from model import Kronos, KronosTokenizer, KronosPredictor
except ImportError:
    print("é”™è¯¯: æ— æ³•å¯¼å…¥Kronosæ¨¡å‹ï¼Œè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)

class StockPredictor:
    """è‚¡ç¥¨é¢„æµ‹å™¨"""
    
    def __init__(self, device="auto", max_context=512, results_dir="my_stock_predictor/prediction_results"):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            device (str): è®¡ç®—è®¾å¤‡ï¼Œå¯ä¸º 'cpu'ã€'cuda:0' æˆ– 'auto'
            max_context (int): æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            results_dir (str): ç»“æœä¿å­˜ç›®å½•
        """
        self.requested_device = device
        self.device = self._resolve_device(device)
        self.max_context = max_context
        self.results_dir = results_dir
        self.model = None
        self.tokenizer = None
        self.predictor = None
        
        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        self.ensure_results_dir()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.load_model()
    
    def ensure_results_dir(self):
        """ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
            print(f"åˆ›å»ºç»“æœç›®å½•: {self.results_dir}")
    
    def _resolve_device(self, device):
        """æ ¹æ®å½“å‰ç¯å¢ƒè§£æå®é™…ä½¿ç”¨çš„è®¾å¤‡"""
        normalized = (device or "auto").lower()

        if normalized == "auto":
            if torch.backends.mps.is_available() and torch.backends.mps.is_built():
                print("âœ… æ£€æµ‹åˆ° Apple Silicon MPSï¼Œè‡ªåŠ¨ä½¿ç”¨ 'mps' è®¾å¤‡ã€‚")
                return "mps"
            elif torch.cuda.is_available():
                print("âœ… æ£€æµ‹åˆ°å¯ç”¨çš„ CUDAï¼Œè‡ªåŠ¨ä½¿ç”¨ 'cuda:0' è®¾å¤‡ã€‚")
                return "cuda:0"
            else:
                print("â„¹ï¸ æœªæ£€æµ‹åˆ° GPU åŠ é€Ÿï¼Œå°†ä½¿ç”¨ CPUã€‚")
                return "cpu"

        if normalized.startswith("cuda"):
            if torch.cuda.is_available():
                return device
            print("âš ï¸ è¯·æ±‚ä½¿ç”¨ CUDAï¼Œä½†å½“å‰ç¯å¢ƒä¸æ”¯æŒï¼Œå·²è‡ªåŠ¨å›é€€åˆ° CPUã€‚")
            return "cpu"

        if normalized == "mps":
            if torch.backends.mps.is_available() and torch.backends.mps.is_built():
                return "mps"
            print("âš ï¸ è¯·æ±‚ä½¿ç”¨ MPS (Apple Silicon)ï¼Œä½†å½“å‰ç¯å¢ƒä¸æ”¯æŒï¼Œå·²è‡ªåŠ¨å›é€€åˆ° CPUã€‚")
            return "cpu"

        return device
    
    def load_model(self):
        """åŠ è½½Kronosæ¨¡å‹"""
        try:
            print(f"æ­£åœ¨åŠ è½½Kronosæ¨¡å‹... (device: {self.device})")

            # è®¾ç½®ç¯å¢ƒå˜é‡è§£å†³SSLé—®é¢˜
            import os
            os.environ['HF_HUB_DISABLE_SSL_VERIFICATION'] = '1'
            os.environ['REQUESTS_CA_BUNDLE'] = ''
            os.environ['SSL_CERT_FILE'] = ''

            # åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹
            self.tokenizer = KronosTokenizer.from_pretrained("NeoQuasar/Kronos-Tokenizer-base")
            self.model = Kronos.from_pretrained("NeoQuasar/Kronos-small")

            # åˆ›å»ºé¢„æµ‹å™¨
            self.predictor = KronosPredictor(
                self.model,
                self.tokenizer,
                device=self.device,
                max_context=self.max_context
            )

            print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")

        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("\nğŸ”§ è§£å†³æ–¹æ¡ˆ:")
            print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            print("  2. å°è¯•ä½¿ç”¨ä»£ç†: export HTTPS_PROXY=http://your-proxy:port")
            print("  3. æˆ–è€…ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°åè®¾ç½® local_files_only=True")
            print("  4. å¦‚æœæ˜¯SSLé—®é¢˜ï¼Œå¯ä»¥å°è¯•: pip install --upgrade requests urllib3")
            raise
    
    def load_data(self, filepath):
        """
        åŠ è½½è‚¡ç¥¨æ•°æ®
        
        Args:
            filepath (str): æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ®
        """
        try:
            print(f"æ­£åœ¨åŠ è½½æ•°æ®: {filepath}")
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(filepath)
            
            # ç¡®ä¿æ—¶é—´æˆ³åˆ—å­˜åœ¨
            if 'timestamps' not in df.columns:
                print("é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸­ç¼ºå°‘timestampsåˆ—")
                return None
            
            # è½¬æ¢æ—¶é—´æˆ³æ ¼å¼
            df['timestamps'] = pd.to_datetime(df['timestamps'])
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
            required_columns = ['timestamps', 'open', 'high', 'low', 'close', 'volume', 'amount']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                print(f"è­¦å‘Š: ç¼ºå°‘åˆ—: {missing_columns}")
                # å°è¯•ç”¨å…¶ä»–åˆ—ååŒ¹é…
                column_mapping = {
                    'Open': 'open',
                    'High': 'high',
                    'Low': 'low',
                    'Close': 'close',
                    'Volume': 'volume',
                    'Amount': 'amount'
                }
                
                for old_col, new_col in column_mapping.items():
                    if old_col in df.columns and new_col not in df.columns:
                        df[new_col] = df[old_col]
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'amount']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # åˆ é™¤æ— æ•ˆæ•°æ®
            df = df.dropna()
            
            # æŒ‰æ—¶é—´æ’åº
            df = df.sort_values('timestamps').reset_index(drop=True)
            
            print(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®")
            print(f"æ—¶é—´èŒƒå›´: {df['timestamps'].min()} åˆ° {df['timestamps'].max()}")
            
            return df
            
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None
    
    def prepare_prediction_data(self, df, lookback=1500, pred_len=96):
        """
        å‡†å¤‡é¢„æµ‹æ•°æ®
        
        Args:
            df (pd.DataFrame): è‚¡ç¥¨æ•°æ®
            lookback (int): å›çœ‹çª—å£å¤§å°
            pred_len (int): é¢„æµ‹é•¿åº¦
            
        Returns:
            tuple: (è¾“å…¥æ•°æ®, è¾“å…¥æ—¶é—´æˆ³, è¾“å‡ºæ—¶é—´æˆ³)
        """
        if len(df) < lookback + pred_len:
            print(f"è­¦å‘Š: æ•°æ®é•¿åº¦({len(df)})å°äºlookback({lookback}) + pred_len({pred_len})")
            # è°ƒæ•´å‚æ•°
            lookback = min(lookback, len(df) // 2)
            pred_len = min(pred_len, len(df) - lookback)
            print(f"è°ƒæ•´å‚æ•°: lookback={lookback}, pred_len={pred_len}")
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        x_df = df.loc[:lookback-1, ['open', 'high', 'low', 'close', 'volume', 'amount']]
        x_timestamp = df.loc[:lookback-1, 'timestamps']
        y_timestamp = df.loc[lookback:lookback+pred_len-1, 'timestamps']
        
        return x_df, x_timestamp, y_timestamp
    
    def predict(self, x_df, x_timestamp, y_timestamp, pred_len, T=1.0, top_p=0.9, sample_count=1):
        """
        è¿›è¡Œé¢„æµ‹
        
        Args:
            x_df (pd.DataFrame): è¾“å…¥ç‰¹å¾
            x_timestamp (pd.Series): è¾“å…¥æ—¶é—´æˆ³
            y_timestamp (pd.Series): é¢„æµ‹æ—¶é—´æˆ³
            pred_len (int): é¢„æµ‹é•¿åº¦
            T (float): é‡‡æ ·æ¸©åº¦
            top_p (float): æ ¸é‡‡æ ·æ¦‚ç‡
            sample_count (int): é‡‡æ ·æ¬¡æ•°
            
        Returns:
            pd.DataFrame: é¢„æµ‹ç»“æœ
        """
        try:
            print("æ­£åœ¨è¿›è¡Œé¢„æµ‹...")
            pred_df = self.predictor.predict(
                df=x_df,
                x_timestamp=x_timestamp,
                y_timestamp=y_timestamp,
                pred_len=pred_len,
                T=T,
                top_p=top_p,
                sample_count=sample_count,
                verbose=True
            )
            
            print("é¢„æµ‹å®Œæˆï¼")
            return pred_df
            
        except Exception as e:
            print(f"é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def plot_prediction(self, historical_df, pred_df, symbol, is_future_forecast=False, save_plot=True, plot_lookback=1500):
        """
        ç»˜åˆ¶é¢„æµ‹ç»“æœ
        """
        try:
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            # å‡†å¤‡ç»˜å›¾æ•°æ®
            start_pred_time = pred_df.index.min()
            historical_plot_df = historical_df[historical_df['timestamps'] < start_pred_time].tail(plot_lookback)
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8), sharex=True)
            
            # --- ä»·æ ¼å›¾ ---
            ax1.plot(historical_plot_df['timestamps'], historical_plot_df['close'], label='å†å²ä»·æ ¼', color='blue', linewidth=1.5)
            ax1.plot(pred_df.index, pred_df['close'], label='é¢„æµ‹ä»·æ ¼', color='red', linewidth=1.5, linestyle='--')
            
            # åœ¨å›æµ‹æ¨¡å¼ä¸‹ï¼Œæ·»åŠ çœŸå®ä»·æ ¼æ›²çº¿
            if not is_future_forecast:
                true_values_df = historical_df[historical_df['timestamps'].isin(pred_df.index)]
                ax1.plot(true_values_df['timestamps'], true_values_df['close'], label='çœŸå®ä»·æ ¼', color='green', linewidth=1.5, alpha=0.7)
            
            ax1.set_ylabel('ä»·æ ¼', fontsize=14)
            ax1.set_title(f'{symbol} è‚¡ç¥¨é¢„æµ‹ç»“æœ', fontsize=16)
            ax1.legend(loc='upper left', fontsize=12)
            ax1.grid(True, alpha=0.3)
            if not historical_plot_df.empty:
                ax1.axvline(historical_plot_df['timestamps'].iloc[-1], color='gray', linestyle='--', linewidth=1)
            
            # --- æˆäº¤é‡å›¾ ---
            ax2.plot(historical_plot_df['timestamps'], historical_plot_df['volume'], label='å†å²æˆäº¤é‡', color='blue', linewidth=1.5)
            ax2.plot(pred_df.index, pred_df['volume'], label='é¢„æµ‹æˆäº¤é‡', color='red', linewidth=1.5, linestyle='--')
            
            if not is_future_forecast:
                true_values_df = historical_df[historical_df['timestamps'].isin(pred_df.index)]
                ax2.plot(true_values_df['timestamps'], true_values_df['volume'], label='çœŸå®æˆäº¤é‡', color='green', linewidth=1.5, alpha=0.7)
            
            ax2.set_ylabel('æˆäº¤é‡', fontsize=14)
            ax2.set_xlabel('æ—¶é—´', fontsize=14)
            ax2.legend(loc='upper left', fontsize=12)
            ax2.grid(True, alpha=0.3)
            if not historical_plot_df.empty:
                ax2.axvline(historical_plot_df['timestamps'].iloc[-1], color='gray', linestyle='--', linewidth=1)
            
            plt.xticks(rotation=30, ha='right')
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            plot_path = None
            if save_plot:
                # --- ä¿®æ­£: åˆ›å»ºè‚¡ç¥¨ä¸“å±çš„ç»“æœå­æ–‡ä»¶å¤¹ ---
                symbol_results_dir = os.path.join(self.results_dir, symbol)
                os.makedirs(symbol_results_dir, exist_ok=True)

                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                plot_filename = f"{symbol}_prediction_chart_{timestamp}.png"
                plot_path = os.path.join(symbol_results_dir, plot_filename)
                plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                print(f"å›¾è¡¨å·²ä¿å­˜: {plot_path}")
            
            plt.show()
            
            return plot_path
            
        except Exception as e:
            print(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {e}")
            return None
    
    def save_prediction_results(self, pred_df, symbol, metadata=None):
        """
        ä¿å­˜é¢„æµ‹ç»“æœ
        
        Args:
            pred_df (pd.DataFrame): é¢„æµ‹ç»“æœ
            symbol (str): è‚¡ç¥¨ä»£ç 
            metadata (dict): å…ƒæ•°æ®
            
        Returns:
            str: ç»“æœæ–‡ä»¶è·¯å¾„
        """
        try:
            # --- ä¿®æ­£: åˆ›å»ºè‚¡ç¥¨ä¸“å±çš„ç»“æœå­æ–‡ä»¶å¤¹ ---
            symbol_results_dir = os.path.join(self.results_dir, symbol)
            os.makedirs(symbol_results_dir, exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜é¢„æµ‹æ•°æ®
            csv_filename = f"{symbol}_prediction_data_{timestamp}.csv"
            csv_path = os.path.join(symbol_results_dir, csv_filename)
            
            # å°†ç´¢å¼•é‡ç½®ä¸ºåˆ—ï¼Œå¹¶ç¡®ä¿åˆ—åä¸º'timestamps'
            save_df = pred_df.reset_index()
            if 'index' in save_df.columns:
                save_df = save_df.rename(columns={'index': 'timestamps'})
            
            save_df.to_csv(csv_path, index=False)
            
            # ä¿å­˜å…ƒæ•°æ®
            if metadata is None:
                metadata = {}
            
            metadata.update({
                'symbol': symbol,
                'prediction_time': timestamp,
                'data_points': len(pred_df),
                'columns': list(pred_df.columns)
            })
            
            json_filename = f"{symbol}_metadata_{timestamp}.json"
            json_path = os.path.join(symbol_results_dir, json_filename)
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ '{symbol_results_dir}' ç›®å½•:")
            print(f"  - æ•°æ®æ–‡ä»¶: {os.path.basename(csv_path)}")
            print(f"  - å…ƒæ•°æ®æ–‡ä»¶: {os.path.basename(json_path)}")
            
            return csv_path
            
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return None
    
    def analyze_prediction(self, historical_df, pred_df, symbol, is_future_forecast):
        """
        åˆ†æé¢„æµ‹ç»“æœ
        """
        try:
            # è·å–å†å²æ•°æ®çš„æœ€åä¸€ä¸ªç‚¹ç”¨äºæ¯”è¾ƒ
            last_historical_point = historical_df.iloc[-1]
            last_close = last_historical_point['close']
            
            # é¢„æµ‹æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
            pred_close_stats = {
                'mean': pred_df['close'].mean(),
                'std': pred_df['close'].std(),
                'min': pred_df['close'].min(),
                'max': pred_df['close'].max(),
                'trend': 'ä¸Šæ¶¨' if pred_df['close'].iloc[-1] > pred_df['close'].iloc[0] else 'ä¸‹è·Œ'
            }
            
            pred_volume_stats = {
                'mean': pred_df['volume'].mean(),
                'std': pred_df['volume'].std(),
                'min': pred_df['volume'].min(),
                'max': pred_df['volume'].max()
            }
            
            # ä»·æ ¼å˜åŒ–åˆ†æ
            # å¦‚æœæ˜¯æœªæ¥é¢„æµ‹ï¼Œä¸æœ€åä¸€ä¸ªå†å²ç‚¹æ¯”è¾ƒ
            # å¦‚æœæ˜¯å›æµ‹ï¼Œä¸é¢„æµ‹å¼€å§‹å‰çš„é‚£ä¸ªç‚¹æ¯”è¾ƒ
            if is_future_forecast:
                comparison_close = last_close
            else:
                # æ‰¾åˆ°é¢„æµ‹å¼€å§‹å‰çš„æœ€åä¸€ä¸ªç‚¹
                comparison_point = historical_df[historical_df['timestamps'] < pred_df.index.min()]
                if not comparison_point.empty:
                    comparison_close = comparison_point.iloc[-1]['close']
                else:
                    comparison_close = last_close # Fallback

            price_change = pred_df['close'].iloc[-1] - comparison_close
            price_change_pct = (price_change / comparison_close) * 100 if comparison_close != 0 else 0
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            analysis = {
                'symbol': symbol,
                'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'historical_last_close': last_close,
                'historical_last_volume': last_historical_point['volume'], # ä½¿ç”¨æœ€åä¸€ä¸ªå†å²ç‚¹çš„æˆäº¤é‡
                'prediction_periods': len(pred_df),
                'price_analysis': {
                    'predicted_last_close': pred_df['close'].iloc[-1],
                    'price_change': price_change,
                    'price_change_percentage': price_change_pct,
                    'trend': pred_close_stats['trend'],
                    'volatility': pred_close_stats['std']
                },
                'volume_analysis': {
                    'predicted_avg_volume': pred_volume_stats['mean'],
                    'volume_trend': 'å¢åŠ ' if pred_volume_stats['mean'] > last_historical_point['volume'] else 'å‡å°‘'
                },
                'statistics': {
                    'close_stats': pred_close_stats,
                    'volume_stats': pred_volume_stats
                }
            }
            
            # æ‰“å°åˆ†æç»“æœ
            print("\n" + "="*60)
            print(f"ğŸ“Š {symbol} é¢„æµ‹åˆ†ææŠ¥å‘Š")
            print("="*60)
            print(f"ğŸ“ˆ ä»·æ ¼è¶‹åŠ¿: {analysis['price_analysis']['trend']}")
            print(f"ğŸ’° é¢„æµ‹ä»·æ ¼å˜åŒ–: {price_change:.4f} ({price_change_pct:.2f}%)")
            print(f"ğŸ“Š ä»·æ ¼æ³¢åŠ¨æ€§: {pred_close_stats['std']:.4f}")
            print(f"ğŸ“ˆ æˆäº¤é‡è¶‹åŠ¿: {analysis['volume_analysis']['volume_trend']}")
            print(f"ğŸ“Š é¢„æµ‹æ•°æ®ç‚¹: {len(pred_df)}")
            print("="*60)
            
            return analysis
            
        except Exception as e:
            print(f"åˆ†æé¢„æµ‹ç»“æœå¤±è´¥: {e}")
            return None
    
    def run_prediction_pipeline(self, historical_df, x_df, x_timestamp, y_timestamp,
                               is_future_forecast, symbol, pred_len,
                               T=1.0, top_p=0.9, sample_count=1, plot_lookback=1500):
        """
        è¿è¡Œå®Œæ•´çš„é¢„æµ‹æµç¨‹
        """
        print(f"ğŸš€ å¼€å§‹ {symbol} çš„é¢„æµ‹æµç¨‹...")
        
        # --- æ ¸å¿ƒä¿®æ­£: ç¡®ä¿ y_timestamp å§‹ç»ˆæ˜¯ Series ---
        # åŸå§‹æ¨¡å‹éœ€è¦ Series ç±»å‹çš„æ—¶é—´æˆ³è¾“å…¥
        if isinstance(y_timestamp, pd.DatetimeIndex):
            y_timestamp_series = pd.Series(y_timestamp, index=y_timestamp)
        else:
            y_timestamp_series = y_timestamp

        # 1. è¿›è¡Œé¢„æµ‹
        pred_df = self.predict(x_df, x_timestamp, y_timestamp_series, pred_len, T, top_p, sample_count)
        if pred_df is None:
            return None
        
        # 2. ç¡®ä¿ pred_df çš„ç´¢å¼•æ˜¯ DatetimeIndex
        pred_df.index = pd.to_datetime(pred_df.index)
        
        # 3. åˆ†æé¢„æµ‹ç»“æœ
        analysis = self.analyze_prediction(historical_df, pred_df, symbol, is_future_forecast)
        
        # 4. ç»˜åˆ¶å›¾è¡¨
        plot_path = self.plot_prediction(historical_df, pred_df, symbol, is_future_forecast, plot_lookback=plot_lookback)
        
        # 5. ä¿å­˜ç»“æœ
        metadata = {
            'analysis': analysis,
            'plot_path': plot_path,
            'parameters': {
                'pred_len': pred_len,
                'T': T,
                'top_p': top_p,
                'sample_count': sample_count,
                'is_future_forecast': is_future_forecast
            }
        }
        
        csv_path = self.save_prediction_results(pred_df, symbol, metadata)
        
        # 6. è¿”å›å®Œæ•´ç»“æœ
        results = {
            'symbol': symbol,
            'prediction': pred_df,
            'analysis': analysis,
            'files': {
                'csv_path': csv_path,
                'plot_path': plot_path
            },
            'metadata': metadata
        }
        
        print(f"âœ… {symbol} é¢„æµ‹æµç¨‹å®Œæˆï¼")
        return results

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Kronos è‚¡ç¥¨é¢„æµ‹å™¨ - ç‹¬ç«‹è¿è¡Œç‰ˆæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python stock_predictor.py                                    # ä½¿ç”¨é»˜è®¤è®¾ç½®è¿è¡Œç¤ºä¾‹
  python stock_predictor.py --device cpu                      # ä½¿ç”¨ CPU è¿è¡Œ
  python stock_predictor.py --device cuda:0                   # ä½¿ç”¨ GPU è¿è¡Œ
  python stock_predictor.py --data-path /path/to/data.csv --symbol 000001  # ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®

å‚æ•°è¯´æ˜:
  device: è®¡ç®—è®¾å¤‡é€‰æ‹©
    - auto: è‡ªåŠ¨æ£€æµ‹ (é»˜è®¤ï¼Œæ¨è)
    - cpu: ä½¿ç”¨ CPU
    - cuda:0: ä½¿ç”¨ç¬¬ä¸€ä¸ª CUDA GPU
    - mps: ä½¿ç”¨ Apple Silicon GPU

  data-path: è‡ªå®šä¹‰æ•°æ®æ–‡ä»¶è·¯å¾„ (å¯é€‰)
    å¦‚æœä¸æŒ‡å®šï¼Œå°†ä½¿ç”¨é¡¹ç›®ä¸­çš„ç¤ºä¾‹æ•°æ®

  symbol: è‚¡ç¥¨ä»£ç  (å¯é€‰)
    ä¸ data-path é…åˆä½¿ç”¨ï¼Œé»˜è®¤ '600977'
        """
    )

    parser.add_argument(
        "--device", "-d",
        default="auto",
        choices=["auto", "cpu", "cuda", "cuda:0", "mps"],
        help="è®¡ç®—è®¾å¤‡ (é»˜è®¤: auto)"
    )

    parser.add_argument(
        "--data-path",
        help="è‡ªå®šä¹‰æ•°æ®æ–‡ä»¶è·¯å¾„ (CSVæ ¼å¼ï¼ŒåŒ…å«OHLCVæ•°æ®)"
    )

    parser.add_argument(
        "--symbol", "-s",
        default="600977",
        help="è‚¡ç¥¨ä»£ç  (é»˜è®¤: 600977)"
    )

    parser.add_argument(
        "--lookback", "-l",
        type=int,
        default=1500,
        help="å†å²æ•°æ®ç‚¹æ•°é‡ (é»˜è®¤: 1500)"
    )

    parser.add_argument(
        "--pred-len", "-p",
        type=int,
        default=96,
        help="é¢„æµ‹æ•°æ®ç‚¹æ•°é‡ (é»˜è®¤: 96)"
    )

    parser.add_argument(
        "--future-forecast",
        action="store_true",
        help="æœªæ¥é¢„æµ‹æ¨¡å¼ (é»˜è®¤: Falseï¼Œå›æµ‹æ¨¡å¼)"
    )

    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    print("="*60)
    print("ğŸ¯ Kronos è‚¡ç¥¨é¢„æµ‹å™¨ - ç‹¬ç«‹è¿è¡Œç‰ˆæœ¬")
    print("="*60)
    print(f"ğŸ“‹ ä½¿ç”¨å‚æ•°: device={args.device}, symbol={args.symbol}")

    # 1. åˆ›å»ºé¢„æµ‹å™¨
    try:
        print(f"\nğŸš€ æ­£åœ¨åˆå§‹åŒ–é¢„æµ‹å™¨ (device: {args.device})...")
        predictor = StockPredictor(device=args.device)
        print("âœ… é¢„æµ‹å™¨åˆå§‹åŒ–æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ é¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        print("\nğŸ”§ å¯èƒ½çš„åŸå› :")
        print("  1. ç¼ºå°‘ä¾èµ–åŒ…ï¼Œè¯·è¿è¡Œ: pip install -r requirements.txt")
        print("  2. Kronos æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print(f"  3. è®¾å¤‡ '{args.device}' ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨ 'cpu'")
        print("\nğŸ’¡ å»ºè®®:")
        print("  python stock_predictor.py --device cpu")
        return

    # 2. ç¡®å®šæ•°æ®æ–‡ä»¶è·¯å¾„
    if args.data_path:
        data_path = args.data_path
        symbol = args.symbol
        print(f"\nğŸ“‚ ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®æ–‡ä»¶: {data_path}")
        print(f"ğŸ“ˆ è‚¡ç¥¨ä»£ç : {symbol}")
    else:
        # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        data_path = os.path.join("examples", "data", "XSHG_5min_600977.csv")
        symbol = "600977"
        print(f"\nğŸ“‚ ä½¿ç”¨ç¤ºä¾‹æ•°æ®æ–‡ä»¶: {data_path}")
        print(f"ğŸ“ˆ è‚¡ç¥¨ä»£ç : {symbol}")

    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        print("\nğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
        if args.data_path:
            print("  1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print("  2. ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—: timestamps, open, high, low, close, volume, amount")
        else:
            print("  1. è¿è¡Œæ•°æ®è·å–è„šæœ¬è·å–è‚¡ç¥¨æ•°æ®:")
            print("     python my_stock_predictor/run_my_prediction.py")
        return

    # 3. åŠ è½½æ•°æ®
    print(f"\nğŸ“– æ­£åœ¨åŠ è½½æ•°æ®...")
    df = predictor.load_data(data_path)
    if df is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        return

    # 4. å‡†å¤‡é¢„æµ‹æ•°æ®
    lookback = args.lookback
    pred_len = args.pred_len
    is_future_forecast = args.future_forecast

    print(f"\nâš™ï¸ é¢„æµ‹å‚æ•°:")
    print(f"   - å†å²æ•°æ®ç‚¹: {lookback}")
    print(f"   - é¢„æµ‹é•¿åº¦: {pred_len}")
    print(f"   - é¢„æµ‹æ¨¡å¼: {'æœªæ¥é¢„æµ‹' if is_future_forecast else 'å†å²å›æµ‹'}")

    # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ
    if len(df) < lookback + pred_len:
        print(f"âš ï¸ è­¦å‘Š: æ•°æ®ç‚¹ä¸è¶³ (éœ€è¦ {lookback + pred_len}, å®é™… {len(df)})")
        # è‡ªåŠ¨è°ƒæ•´å‚æ•°
        available_points = len(df)
        lookback = min(lookback, available_points // 2)
        pred_len = min(pred_len, available_points - lookback)
        print(f"ğŸ”§ è‡ªåŠ¨è°ƒæ•´å‚æ•°: lookback={lookback}, pred_len={pred_len}")

    x_df, x_timestamp, y_timestamp = predictor.prepare_prediction_data(df, lookback, pred_len)

    # 5. è¿è¡Œé¢„æµ‹æµç¨‹
    print("\nğŸ”® å¼€å§‹é¢„æµ‹æµç¨‹...")
    start_time = datetime.now()

    results = predictor.run_prediction_pipeline(
        historical_df=df,
        x_df=x_df,
        x_timestamp=x_timestamp,
        y_timestamp=y_timestamp,
        is_future_forecast=is_future_forecast,
        symbol=symbol,
        pred_len=pred_len,
        T=1.0,
        top_p=0.9,
        sample_count=1,
        plot_lookback=lookback
    )

    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()

    if results:
        print(f"\nğŸ‰ é¢„æµ‹å®Œæˆï¼ç”¨æ—¶ {duration:.1f} ç§’")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ° prediction_results/{symbol}/ ç›®å½•")
        print("   - æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’Œæ•°æ®æ–‡ä»¶")
        # æ‰“å°ç»“æœæ¦‚è§ˆ
        analysis = results.get('analysis', {})
        if analysis:
            price_change_pct = analysis.get('price_analysis', {}).get('price_change_percentage', 0)
            trend = analysis.get('price_analysis', {}).get('trend', 'æœªçŸ¥')
            print("\nğŸ“Š é¢„æµ‹æ¦‚è§ˆ:")
            print(f"   - ä»·æ ¼å˜åŒ–: {price_change_pct:.2f}%")
            print(f"   - è¶‹åŠ¿: {trend}")
    else:
        print(f"\nâŒ é¢„æµ‹æµç¨‹å¤±è´¥ï¼Œç”¨æ—¶ {duration:.1f} ç§’")

if __name__ == "__main__":
    main()
