#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================
=== Kronos è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ - ç»Ÿä¸€æ‰§è¡Œè„šæœ¬ ===
================================================

è¿™æ˜¯æ‚¨çš„ä¸»è¦é¢„æµ‹å…¥å£ç‚¹ã€‚
æ‚¨åªéœ€ä¿®æ”¹ä¸‹é¢çš„ `PREDICTION_CONFIG` éƒ¨åˆ†ï¼Œ
ç„¶åç›´æ¥è¿è¡Œæ­¤è„šæœ¬å³å¯ã€‚

ç”¨æ³•:
    python my_stock_predictor/run_my_prediction.py                # é»˜è®¤é¢„æµ‹æœªæ¥
    python my_stock_predictor/run_my_prediction.py --mode future
    python my_stock_predictor/run_my_prediction.py --mode backtest  # ä»…æ‰§è¡Œå›æµ‹

    python my_stock_predictor/run_my_prediction.py --mode tune è‡ªåŠ¨å¯»æ‰¾æœ€ä½³å‚æ•° (fun run_tuning)
"""

import argparse
import math
import os
import sys
import re
import pandas as pd
from datetime import datetime, timedelta

# ç¡®ä¿è„šæœ¬å¯ä»¥æ‰¾åˆ°æˆ‘ä»¬åˆ›å»ºçš„æ¨¡å—
# è¿™å°†å½“å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•æ·»åŠ åˆ°Pythonçš„æœç´¢è·¯å¾„ä¸­
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from stock_data_fetcher import StockDataFetcher
from stock_predictor import StockPredictor
from utils.technical_analysis import TechnicalAnalyzer
from constants import (
    TRADING_MINUTES_PER_DAY,
    TRADING_DAYS_PER_MONTH,
    TRADING_DAYS_RATIO
)

# ==============================================================================
# === é¢„æµ‹é…ç½® ===
# ==============================================================================
# è®¾å¤‡é…ç½® - æ ¹æ®ä½ çš„ç¡¬ä»¶æƒ…å†µé€‰æ‹©
import os
# è®¾ç½®è®¾å¤‡é€‰æ‹©:
# 'auto' = è‡ªåŠ¨æ£€æµ‹ (æ¨è)
# 'cpu' = å¼ºåˆ¶ä½¿ç”¨CPU (ç¨³å®šä½†è¾ƒæ…¢)
# 'cuda' = NVIDIA GPU
# 'mps' = Apple Silicon GPU (å¦‚æœé‡åˆ°MPSå†…å­˜é—®é¢˜ï¼Œæ”¹ç”¨'cpu')
# os.environ['DEVICE'] = 'cpu'  # ä½ æœ‰32GBå†…å­˜ï¼ŒCPUæ¨¡å¼åº”è¯¥æ²¡é—®é¢˜

# è®¾å¤‡é€‰æ‹©é…ç½®
# é€‰é¡¹1: è‡ªåŠ¨æ£€æµ‹ (æ¨èï¼Œä¼˜å…ˆä½¿ç”¨MPSï¼Œå†…å­˜ä¸è¶³æ—¶è‡ªåŠ¨åˆ‡æ¢CPU)
os.environ['DEVICE'] = 'auto'

# é€‰é¡¹2: ç›´æ¥ä½¿ç”¨CPU (ç¨³å®šä½†è¾ƒæ…¢ï¼Œé€‚åˆå¤§å†…å­˜ä½¿ç”¨åœºæ™¯)
# os.environ['DEVICE'] = 'cpu'

# é€‰é¡¹3: å¼ºåˆ¶ä½¿ç”¨MPS (ä»…åœ¨ç¡®è®¤MPSå†…å­˜å……è¶³æ—¶ä½¿ç”¨)
# os.environ['DEVICE'] = 'mps'

"""
è¶…çŸ­çº¿ / æ—¥å†…äº¤æ˜“ (å½“å‰é…ç½®)
é€‚åˆäººç¾¤ï¼šç›¯ç›˜æ—¶é—´å¤šï¼Œå–œæ¬¢æŠ“æ—¥å†…æ³¢åŠ¨ï¼Œåš T+0 æˆ–éš”æ—¥è¶…çŸ­çº¿ã€‚

ç‰¹ç‚¹ï¼šååº”æå¿«ï¼Œä½†å™ªéŸ³å¤šï¼Œå®¹æ˜“è¢«å‡åŠ¨ä½œéª—ã€‚
æ¨èå‚æ•°ï¼š
python
"period": "5",              # 5åˆ†é’Ÿçº¿
"lookback_duration": "20d", # å›æº¯20å¤© (çº¦1000ä¸ªç‚¹)
"pred_len_duration": "1d",  # é¢„æµ‹æœªæ¥1å¤© (çº¦48ä¸ªç‚¹)
"T": 0.2,                   # ä½æ¸©ï¼Œæ±‚ç¨³
===================================================
çŸ­çº¿æ³¢æ®µ (æœ€æ¨èæ–°æ‰‹/ä¸Šç­æ—)
é€‚åˆäººç¾¤ï¼šæ¯å¤©çœ‹ä¸€çœ¼ï¼ŒæŒè‚¡ 3-5 å¤©ï¼ŒæŠ“å‘¨çº§åˆ«çš„æ³¢æ®µã€‚

ç‰¹ç‚¹ï¼šè¿‡æ»¤äº†æ—¥å†…çš„ç»†å¾®å™ªéŸ³ï¼Œä¿¡å·æ›´ç¨³ï¼Œèƒœç‡é€šå¸¸æ¯”5åˆ†é’Ÿçº¿æ›´é«˜ã€‚
æ¨èå‚æ•°ï¼š
python
"period": "60",             # 60åˆ†é’Ÿçº¿ (1å°æ—¶)
"lookback_duration": "60d", # å›æº¯60å¤© (çº¦240ä¸ªç‚¹ï¼Œè¦†ç›–ä¸€ä¸ªå­£åº¦)
"pred_len_duration": "5d",  # é¢„æµ‹æœªæ¥5å¤© (çº¦20ä¸ªç‚¹ï¼Œä¸€å‘¨)
"T": 0.7,                   # ç¨å¾®ç»™ä¸€ç‚¹çµæ´»æ€§
===================================================
é€‚åˆäººç¾¤ï¼šä¸å¸¸çœ‹ç›˜ï¼ŒæŒè‚¡ 1-3 ä¸ªæœˆï¼ŒæŠ“å¤§è¶‹åŠ¿ã€‚

ç‰¹ç‚¹ï¼šéå¸¸ç¨³å¥ï¼Œå¿½ç•¥çŸ­æœŸæ³¢åŠ¨ï¼Œåªçœ‹å¤§æ–¹å‘ã€‚
æ¨èå‚æ•°ï¼š
python
"period": "D",              # æ—¥çº¿
"lookback_duration": "250d",# å›æº¯250å¤© (çº¦1å¹´)
"pred_len_duration": "20d", # é¢„æµ‹æœªæ¥20å¤© (çº¦1ä¸ªæœˆ)
"T": 0.4,                   # å…è®¸æ¨¡å‹å‘æŒ¥æ›´å¤šâ€œæƒ³è±¡åŠ›â€æ¥æ•æ‰è¶‹åŠ¿
"""

PREDICTION_CONFIG = {
    # --- è‚¡ç¥¨ä¿¡æ¯ ---
    "symbol": "300708",          # è‚¡ç¥¨ä»£ç  (ä¾‹å¦‚: Aè‚¡ '600519', ç¾è‚¡ 'NVDA')
    "source": "baostock",        # æ•°æ®æº ('baostock' for Aè‚¡æ¨è, 'akshare' for Aè‚¡å¤‡ç”¨, 'yfinance' for ç¾è‚¡/å…¨çƒ)
    
    # --- æ•°æ®è·å–æ—¶é—´èŒƒå›´ ---
    "start_date": None,         # æ•°æ®å¼€å§‹æ—¥æœŸ (None è¡¨ç¤ºè‡ªåŠ¨æ ¹æ® fallback_fetch_days è®¡ç®—)
    "end_date": None,           # æ•°æ®ç»“æŸæ—¥æœŸ (None è¡¨ç¤ºä½¿ç”¨å½“å‰æ—¥æœŸ)
    "period": "60",             # æ•°æ®é¢‘ç‡ ('5', '15', '30', '60' for åˆ†é’Ÿ, 'D' for æ—¥çº¿) - åˆ‡æ¢ä¸º60åˆ†é’Ÿçº¿

    # --- é¢„æµ‹å‚æ•° (ä½¿ç”¨å¸¦æœ‰å•ä½çš„æ—¶é—´å­—ç¬¦ä¸²) ---
    "lookback_duration": "120d",   # å›æº¯æ—¶é•¿ (å•ä½: d=å¤©, h=å°æ—¶, M=æœˆ) - 120å¤©çº¦480ä¸ªç‚¹ï¼Œå®Œç¾åˆ©ç”¨æ¨¡å‹ä¸Šä¸‹æ–‡(512)
    "pred_len_duration": "5d",    # é¢„æµ‹æ—¶é•¿ (å•ä½: d=å¤©, h=å°æ—¶, M=æœˆ) - é¢„æµ‹æœªæ¥5å¤© (çº¦20ä¸ªç‚¹)

    # --- æ¨¡å‹é«˜çº§å‚æ•° (MPSä¼˜åŒ–é…ç½®) ---
    "T": 0.2,                  # é‡‡æ ·æ¸©åº¦ (ç¨å¾®ç»™ä¸€ç‚¹çµæ´»æ€§)
    "top_p": 0.8,              # æ ¸é‡‡æ ·æ¦‚ç‡ (é€‚åº¦å®½æ¾ï¼Œå…è®¸ä¸€å®šçµæ´»æ€§)
    "sample_count": 5,          # é¢„æµ‹è·¯å¾„æ•°é‡ (ç”¨æˆ·è®¾å¤‡æ”¯æŒæœ€å¤§5ï¼Œå¢åŠ è·¯å¾„æ•°å¯æé«˜ç¨³å®šæ€§)
    "enable_adaptive_tuning": False,  # ç¦ç”¨è‡ªé€‚åº”å‚æ•°è°ƒä¼˜ï¼Œä½¿ç”¨æˆ‘ä»¬è®¾å®šçš„ä¼˜åŒ–å‚æ•°

    # --- æ•°æ®é¢„å¤„ç†å¢å¼º ---
    "enable_advanced_preprocessing": True,  # å¯ç”¨é«˜çº§æ•°æ®é¢„å¤„ç†
    "price_normalization": "robust",       # ä»·æ ¼å½’ä¸€åŒ–æ–¹æ³•: 'standard', 'robust', 'none'
    "trend_adjustment": False,             # ç¦ç”¨è¶‹åŠ¿è°ƒæ•´ (ç›´æ¥é¢„æµ‹ä»·æ ¼ï¼Œé¿å…å¹³æ»‘è¿‡åº¦)
    "volatility_filter": True,             # å¯ç”¨æ³¢åŠ¨ç‡è¿‡æ»¤

    # --- æ–°å¢: æ˜¯å¦å¼ºåˆ¶åˆ·æ–° ---
    "force_refetch": False,     # è®¾ç½®ä¸º True å¯å¿½ç•¥æœ¬åœ°ç¼“å­˜ï¼Œå¼ºåˆ¶ä»ç½‘ç»œè·å–æœ€æ–°æ•°æ®
    # --- æ•°æ®æ–°é²œåº¦æ§åˆ¶ ---
    "min_data_freshness_days": 5,   # å…è®¸çš„æœ€å¤§æ•°æ®æ»åå¤©æ•°
    "fallback_fetch_days": 150,     # å½“æ•°æ®è¿‡æ—§æ—¶é‡æ–°æ‹‰å–çš„æ—¶é—´èŒƒå›´(å¤©æ•°) - è°ƒæ•´ä¸º150å¤©ä»¥è¦†ç›–120å¤©å›æº¯
    
    # --- å›¾è¡¨æ˜¾ç¤ºä¼˜åŒ– ---
    "plot_lookback_days": 30,       # å›¾è¡¨æ˜¾ç¤ºçš„å†å²å¤©æ•° (æ˜¾ç¤ºå®Œæ•´å›æº¯æœŸ)
    "enable_focus_mode": True,       # å¯ç”¨ä¸“æ³¨æ¨¡å¼ï¼Œåªæ˜¾ç¤ºé¢„æµ‹ç›¸å…³åŒºåŸŸ
    "prediction_highlight": True,    # é«˜äº®é¢„æµ‹åŒºåŸŸ
}
# ==============================================================================

class UnifiedPredictor:
    def __init__(self):
        self.fetcher = StockDataFetcher()

    def _calculate_steps(self, duration_str, period):
        """
        æ ¹æ®æ—¶é—´å‘¨æœŸå­—ç¬¦ä¸²å’Œæ•°æ®é¢‘ç‡è®¡ç®—æ‰€éœ€çš„æ­¥æ•°(æ•°æ®ç‚¹æ•°é‡)ã€‚
        """
        if not isinstance(duration_str, str):
            print(f"âŒ é”™è¯¯: æ—¶é—´å‘¨æœŸ '{duration_str}' å¿…é¡»æ˜¯å­—ç¬¦ä¸²ã€‚")
            return None

        duration_str = duration_str.lower().strip()
        match = re.match(r"(\d+)([dhm])", duration_str)

        if not match:
            print(f"âŒ é”™è¯¯: æ— æ³•è§£ææ—¶é—´å‘¨æœŸå­—ç¬¦ä¸² '{duration_str}'ã€‚è¯·ä½¿ç”¨å¦‚ '30d', '4h', '1M' çš„æ ¼å¼ã€‚")
            return None

        value, unit = int(match.group(1)), match.group(2)

        # --- åŸºäºæ•°æ®é¢‘ç‡(period)è¿›è¡Œè®¡ç®— ---
        if period == 'D': # æ—¥çº¿æ•°æ®
            if unit == 'd':
                return value
            elif unit == 'm':
                return value * TRADING_DAYS_PER_MONTH
            else: # 'h'
                print(f"âš ï¸ è­¦å‘Š: æ—¥çº¿æ•°æ®é¢‘ç‡ä¸æ”¯æŒæŒ‰å°æ—¶('{duration_str}')è®¡ç®—ï¼Œå°†æŒ‰å¤©å¤„ç†ã€‚")
                return value
        
        else: # åˆ†é’Ÿæ•°æ®
            try:
                minutes_per_step = int(period)
                steps_per_day = TRADING_MINUTES_PER_DAY // minutes_per_step
                
                if unit == 'd':
                    return value * steps_per_day
                elif unit == 'm':
                    return value * TRADING_DAYS_PER_MONTH * steps_per_day
                elif unit == 'h':
                    return value * (60 // minutes_per_step)

            except (ValueError, ZeroDivisionError):
                print(f"âŒ é”™è¯¯: æ— æ•ˆçš„åˆ†é’Ÿçº¿å‘¨æœŸ '{period}'ã€‚")
                return None

    def run_prediction(self, config):
        """
        æ ¹æ®é…ç½®è¿è¡Œå®Œæ•´çš„è·å–æ•°æ®å’Œé¢„æµ‹æµç¨‹ã€‚
        """
        print("ğŸš€ å¼€å§‹æ‰§è¡Œè‚¡ç¥¨é¢„æµ‹æµç¨‹...")
        print("="*60)
        print(f"ğŸ¯ ç›®æ ‡è‚¡ç¥¨: {config['symbol']} ({config['source']})")
        print("="*60)

        is_future_mode = config.get("forecast_future", False)

        # === æ–°å¢: æ™ºèƒ½è®¡ç®—å›æº¯å’Œé¢„æµ‹æ­¥æ•° ===
        print("ğŸ§  æ­£åœ¨æ™ºèƒ½è®¡ç®—å›æº¯å’Œé¢„æµ‹æ­¥æ•°...")
        lookback_steps = self._calculate_steps(config['lookback_duration'], config['period'])
        pred_len_steps = self._calculate_steps(config['pred_len_duration'], config['period'])
        
        if lookback_steps is None or pred_len_steps is None:
            print("âŒ æ— æ³•è§£ææ—¶é—´å‘¨æœŸå­—ç¬¦ä¸²ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
            return
            
        print(f"   - æ•°æ®é¢‘ç‡: {config['period']}")
        print(f"   - å›æº¯æ—¶é•¿ '{config['lookback_duration']}' -> è®¡ç®—ä¸º {lookback_steps} ä¸ªæ•°æ®ç‚¹")
        print(f"   - é¢„æµ‹æ—¶é•¿ '{config['pred_len_duration']}' -> è®¡ç®—ä¸º {pred_len_steps} ä¸ªæ•°æ®ç‚¹")
        print("="*60)

        required_points_total = lookback_steps + pred_len_steps
        minimum_points_needed = lookback_steps if is_future_mode else required_points_total

        # === æ™ºèƒ½é¢„æ£€ï¼šæå‰æ£€æµ‹æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ ===
        print("ğŸ” æ­£åœ¨è¿›è¡Œæ•°æ®å¯ç”¨æ€§é¢„æ£€...")
        precheck_points_needed = minimum_points_needed
        precheck_days = self._estimate_required_days(int(precheck_points_needed * 1.2), config['period'])  # å¤šè·å–20%ä½œä¸ºç¼“å†²

        # å°†'period'è½¬æ¢ä¸ºæ•°æ®æºèƒ½ç†è§£çš„æ ¼å¼
        period_map = {'5': '5m', '15': '15m', '30': '30m', '60': '60m', 'D': '1d'}
        precheck_period = config['period']
        if config['source'] == 'yfinance':
            precheck_period = period_map.get(config['period'], '1d')

        print(f"   - é¢„æ£€ç›®æ ‡: è‡³å°‘{precheck_points_needed}ä¸ªæ•°æ®ç‚¹ï¼Œä¼°ç®—éœ€è¦{precheck_days}å¤©æ•°æ®")

        precheck_df, _, _ = self.fetcher.get_stock_data(
            symbol=config['symbol'],
            source=config['source'],
            start_date=None,
            end_date=None,
            period=precheck_period,
            save=False,  # é¢„æ£€ä¸ä¿å­˜
            force_refetch=False,
            min_fresh_days=config.get('min_data_freshness_days'),
            fallback_days=precheck_days
        )

        if precheck_df is not None and len(precheck_df) >= precheck_points_needed:
            print(f"   - âœ… é¢„æ£€é€šè¿‡: è·å–åˆ°{len(precheck_df)}ä¸ªæ•°æ®ç‚¹ï¼Œæ»¡è¶³æœ€ä½è¦æ±‚")
            if not is_future_mode and len(precheck_df) < required_points_total:
                print(f"   - âš ï¸ æ³¨æ„: æ•°æ®ç‚¹({len(precheck_df)})ä¸è¶³ä»¥å®Œæ•´å›æµ‹({required_points_total})ï¼Œå°†ä»…è¿›è¡Œæœªæ¥é¢„æµ‹")
                is_future_mode = True
                config["forecast_future"] = True
                print(f"   - ğŸ”„ å·²åˆ‡æ¢åˆ°æœªæ¥é¢„æµ‹æ¨¡å¼")
        else:
            print(f"   - âŒ é¢„æ£€å¤±è´¥: åªæœ‰{len(precheck_df) if precheck_df is not None else 0}ä¸ªæ•°æ®ç‚¹")
            if precheck_df is None:
                print("âŒ æ•°æ®è·å–å®Œå…¨å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                return
            else:
                print(f"âš ï¸ æ•°æ®ä¸è¶³ï¼Œå°†å°è¯•æ‰©å±•è·å–èŒƒå›´...")
        print("="*60)

        # === æ­¥éª¤ 1: è·å–æ•°æ® ===
        print("ğŸ“Š æ­£åœ¨è·å–æ•°æ®...")
        print(f"   - å½“å‰æ¨¡å¼: {'æœªæ¥é¢„æµ‹' if is_future_mode else 'å›æµ‹'}")
        print(f"   - è‡³å°‘éœ€è¦ {minimum_points_needed} ä¸ªæ•°æ®ç‚¹")
        
        # å°†'period'è½¬æ¢ä¸º'akshare'å’Œ'yfinance'èƒ½ç†è§£çš„æ ¼å¼
        period_map = {'5': '5m', '15': '15m', '30': '30m', '60': '60m', 'D': '1d'}
        fetch_period = config['period']
        if config['source'] == 'yfinance':
            fetch_period = period_map.get(config['period'], '1d')

        df, filepath, metadata = self.fetcher.get_stock_data(
            symbol=config['symbol'],
            source=config['source'],
            start_date=config['start_date'],
            end_date=config['end_date'],
            period=fetch_period,
            save=True,
            force_refetch=config.get('force_refetch', False),
            min_fresh_days=config.get('min_data_freshness_days'),
            fallback_days=config.get('fallback_fetch_days')
        )

        if filepath is None or df is None:
            print("âŒ è·å–æ•°æ®å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
            print("ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            print(f"  2. æ£€æŸ¥è‚¡ç¥¨ä»£ç  '{config['symbol']}' æ˜¯å¦æ­£ç¡®")
            print(f"  3. æ£€æŸ¥æ•°æ®æº '{config['source']}' æ˜¯å¦å¯ç”¨")
            print(f"  4. å°è¯•æ›´æ¢æ•°æ®æºæˆ–è°ƒæ•´æ—¶é—´èŒƒå›´")
            return

        if len(df) < minimum_points_needed:
            print(f"âš ï¸ å½“å‰æ•°æ®ç‚¹ {len(df)} å°‘äºæ‰€éœ€çš„ {minimum_points_needed}ï¼Œå°è¯•æ‰©å±•æŠ“å–èŒƒå›´...")
            minimum_days = self._estimate_required_days(minimum_points_needed, config['period'])
            fallback_days = config.get('fallback_fetch_days')
            if fallback_days is None:
                fallback_days = minimum_days
            else:
                fallback_days = max(fallback_days, minimum_days)

            df, filepath, metadata = self.fetcher.get_stock_data(
                symbol=config['symbol'],
                source=config['source'],
                start_date=None,
                end_date=None,
                period=fetch_period,
                save=True,
                force_refetch=True,
                min_fresh_days=config.get('min_data_freshness_days'),
                fallback_days=fallback_days
            )

            if filepath is None or df is None:
                print("âŒ æ‰©å±•æŠ“å–ä»å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                print("ğŸ”§ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
                print("  1. æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç½‘ç»œé™åˆ¶æˆ–APIé™åˆ¶")
                print(f"  2. å‡å°‘é¢„æµ‹æ—¶é•¿æˆ–å¢åŠ æ•°æ®é¢‘ç‡ä» '{config['period']}' åˆ°æ›´ç²—çš„æ—¶é—´ç²’åº¦")
                print(f"  3. å‡å°‘å›æº¯æ—¶é•¿ä» '{config['lookback_duration']}' åˆ°æ›´çŸ­çš„æ—¶é—´èŒƒå›´")
                print("  4. ä½¿ç”¨ä¸åŒçš„æ•°æ®æº")
                return

            if len(df) < minimum_points_needed:
                print(f"âŒ æ‰©å±•åæ•°æ®é‡ {len(df)} ä»ä¸è¶³ä»¥æ”¯æŒå½“å‰é…ç½®(éœ€è¦ {minimum_points_needed})")
                print("ğŸ”§ å‚æ•°è°ƒæ•´å»ºè®®:")
                print(f"  1. å½“å‰éœ€è¦çº¦ {self._estimate_required_days(minimum_points_needed, config['period'])} å¤©çš„å†å²æ•°æ®")
                print("  2. å»ºè®®å‡å°‘ lookback_duration æˆ– pred_len_duration å‚æ•°")
                print("  3. æˆ–ä½¿ç”¨æ›´å¤§çš„æ•°æ®é¢‘ç‡é—´éš”")
                return

        print(f"âœ… æ•°æ®è·å–æˆåŠŸï¼Œå·²ä¿å­˜/åŠ è½½äº: {filepath}")
        print("="*60)

        # === æ•°æ®é‡æ£€æŸ¥å’Œæ™ºèƒ½è£å‰ª ===
        print("="*60)
        print("âœ‚ï¸ æ­£åœ¨æ£€æŸ¥æ•°æ®é‡æ˜¯å¦æ»¡è¶³é¢„æµ‹éœ€æ±‚...")
        original_rows = len(df)
        print(f"   - ç”¨äºåˆ†æçš„åŸå§‹æ•°æ®å…±æœ‰ {original_rows} æ¡ã€‚")

        # è®¡ç®—æ‰€éœ€çš„æœ€å°‘æ•°æ®é‡
        required_total = lookback_steps + pred_len_steps
        print(f"   - é¢„æµ‹é…ç½®éœ€è¦è‡³å°‘ {required_total} ä¸ªæ•°æ®ç‚¹ (å›æº¯{lookback_steps} + é¢„æµ‹{pred_len_steps})")

        # å¯¹äºå›æµ‹æ¨¡å¼ï¼Œéœ€è¦æ›´å¤šæ•°æ®
        if not is_future_mode:
            if original_rows < required_total:
                print(f"   - âš ï¸ å›æµ‹æ¨¡å¼æ•°æ®ä¸è¶³ï¼Œå°†è‡ªåŠ¨åˆ‡æ¢ä¸ºæœªæ¥é¢„æµ‹æ¨¡å¼")
                print(f"     (éœ€è¦{required_total}ç‚¹ï¼Œå®é™…{original_rows}ç‚¹)")
                is_future_mode = True
                config["forecast_future"] = True
            else:
                print("   - âœ… å›æµ‹æ¨¡å¼æ•°æ®å……è¶³")
        else:
            print("   - âœ… æœªæ¥é¢„æµ‹æ¨¡å¼")

        # æ™ºèƒ½è£å‰ªæ•°æ®ï¼ˆä¿ç•™è¶³å¤Ÿçš„å†å²æ•°æ®ï¼‰
        min_required = max(required_total, 5000)  # è‡³å°‘ä¿ç•™5000ç‚¹æˆ–æ‰€éœ€ç‚¹æ•°
        if original_rows > min_required:
            # å¯¹äºæœªæ¥é¢„æµ‹ï¼Œä¿ç•™æœ€æ–°çš„æ•°æ®
            if is_future_mode:
                keep_rows = min(original_rows, 10000)  # æœ€å¤šä¿ç•™10000ç‚¹
            else:
                # å¯¹äºå›æµ‹ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„è¿ç»­æ•°æ®
                keep_rows = max(required_total + 1000, min_required)  # å¤šä¿ç•™ä¸€äº›ç¼“å†²

            df = df.tail(keep_rows).reset_index(drop=True)
            print(f"   - å·²è£å‰ªæ•°æ®è‡³æœ€æ–°çš„ {len(df)} æ¡ï¼Œä¿ç•™è¶³å¤Ÿçš„å†å²ä¿¡æ¯ã€‚")
        else:
            print(f"   - æ•°æ®é‡é€‚ä¸­ ({len(df)} æ¡)ï¼Œæ— éœ€è£å‰ªã€‚")

        # === æ–°å¢: è®¡ç®—å¹¶æ˜¾ç¤ºå½“å‰æŠ€æœ¯æŒ‡æ ‡ ===
        print("="*60)
        print("ğŸ“ˆ è®¡ç®—å½“å‰æŠ€æœ¯æŒ‡æ ‡ (åŸºäºå†å²æ•°æ®)...")
        try:
            # è®¡ç®—æŒ‡æ ‡
            tech_df = TechnicalAnalyzer.add_all_indicators(df)
            last_row = tech_df.iloc[-1]
            
            print(f"   - å½“å‰ä»·æ ¼: {last_row['close']:.2f}")
            print(f"   - MA5:  {last_row['MA5']:.2f}")
            print(f"   - MA10: {last_row['MA10']:.2f}")
            print(f"   - MA20: {last_row['MA20']:.2f}")
            print(f"   - MACD: {last_row['MACD']:.4f} (Signal: {last_row['MACD_Signal']:.4f}, Hist: {last_row['MACD_Hist']:.4f})")
            print(f"   - RSI:  {last_row['RSI']:.2f}")
            print(f"   - KDJ:  K={last_row['K']:.1f}, D={last_row['D']:.1f}, J={last_row['J']:.1f}")
            print(f"   - BOLL: ä¸Šè½¨={last_row['BB_Upper']:.2f}, ä¸­è½¨={last_row['BB_Middle']:.2f}, ä¸‹è½¨={last_row['BB_Lower']:.2f}")
            
            # è·å–æ¨¡å‹é¢„æµ‹è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            # æ³¨æ„ï¼šæ­¤æ—¶æ¨¡å‹è¿˜æ²¡è·‘ï¼Œæˆ‘ä»¬åªèƒ½å…ˆåŸºäºæŠ€æœ¯é¢åˆ†æï¼Œæˆ–è€…ç­‰æ¨¡å‹è·‘å®Œå†ç»“åˆ
            # è¿™é‡Œæˆ‘ä»¬å…ˆåšçº¯æŠ€æœ¯é¢åˆ†æï¼Œç­‰æ¨¡å‹è·‘å®Œåå†åšç»“åˆåˆ†æä¼šæ›´å‡†ç¡®ï¼Œä½†ä¸ºäº†ç”¨æˆ·ä½“éªŒï¼Œå…ˆåœ¨è¿™é‡Œå±•ç¤ºæŠ€æœ¯é¢ä¿¡å·
            
            analysis_result = TechnicalAnalyzer.analyze_market_condition(tech_df)
            
            print("-" * 40)
            print("ğŸ” æŠ€æœ¯é¢ä¿¡å·:")
            for signal in analysis_result['signals']:
                print(f"   âœ… {signal}")
            
            if analysis_result['warnings']:
                print("âš ï¸ é£é™©è­¦ç¤º:")
                for warning in analysis_result['warnings']:
                    print(f"   âš ï¸ {warning}")
                    
            print("-" * 40)
            
        except Exception as e:
            print(f"   âš ï¸ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
 
        # === æ­¥éª¤ 2: å‡†å¤‡é¢„æµ‹ ===
        print("ğŸ¤– æ­£åœ¨å‡†å¤‡é¢„æµ‹...")

        ground_truth = None  # åˆå§‹åŒ–ground_truthå˜é‡
        
        if is_future_mode:
            # --- æœªæ¥é¢„æµ‹æ¨¡å¼ ---
            print("   - æ¨¡å¼: æœªæ¥é¢„æµ‹")
            # é¢„æµ‹çš„è¾“å…¥æ•°æ®æ˜¯æ‰€æœ‰æˆ‘ä»¬èƒ½è·å–åˆ°çš„å†å²æ•°æ®
            x_df = df[['open', 'high', 'low', 'close', 'volume', 'amount']]
            x_timestamp = df['timestamps']
            # ç”Ÿæˆæœªæ¥çš„æ—¶é—´æˆ³
            y_timestamp = self._generate_future_timestamps(df['timestamps'].iloc[-1], pred_len_steps, config['period'])
            if y_timestamp is None:
                print("âŒ ç”Ÿæˆæœªæ¥æ—¶é—´æˆ³å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                return
            print(f"   - å·²ç”Ÿæˆ {len(y_timestamp)} ä¸ªæœªæ¥æ—¶é—´ç‚¹ç”¨äºé¢„æµ‹ã€‚")
        else:
            # --- å›æµ‹æ¨¡å¼ ---
            print("   - æ¨¡å¼: å›æµ‹ (ä¸å†å²æ•°æ®å¯¹æ¯”)")
            # ä½¿ç”¨æ–°çš„prepare_backtest_dataæ–¹æ³•æ­£ç¡®åˆ‡åˆ†æ•°æ®
            if len(df) < required_points_total:
                print(f"âŒ é”™è¯¯: æ•°æ®ä¸è¶³ä»¥è¿›è¡Œå›æµ‹ã€‚æ‰€éœ€æ•°æ®ç‚¹: {required_points_total}, å®é™…æ‹¥æœ‰: {len(df)}")
                return

            subset_df = df.tail(required_points_total).reset_index(drop=True)
            # âš ï¸ è¿™é‡Œéœ€è¦å…ˆåˆ›å»ºä¸´æ—¶predictoræ¥è°ƒç”¨prepare_backtest_dataæ–¹æ³•
            # ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œæˆ‘ä»¬æ‰‹åŠ¨åˆ‡åˆ†ä½†ä¿å­˜ground_truth
            x_df = subset_df.iloc[:lookback_steps][['open', 'high', 'low', 'close', 'volume', 'amount']].copy()
            x_timestamp = subset_df.iloc[:lookback_steps]['timestamps'].copy()
            y_timestamp = subset_df.iloc[lookback_steps:lookback_steps+pred_len_steps]['timestamps'].copy()
            
            # ã€å…³é”®ä¿®å¤ã€‘ä¿å­˜ground truthç”¨äºåç»­éªŒè¯
            ground_truth = subset_df.iloc[lookback_steps:lookback_steps+pred_len_steps][['open', 'high', 'low', 'close', 'volume', 'amount']].copy()
            ground_truth.index = y_timestamp.values
            print(f"   - âœ… å·²å‡†å¤‡å›æµ‹æ•°æ®å¹¶ä¿å­˜çœŸå®å€¼ç”¨äºéªŒè¯")

        # æŒ‡å®šç»“æœä¿å­˜ç›®å½•ä¸ºå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ä¸‹çš„ prediction_results
        results_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "prediction_results")
        predictor = StockPredictor(
            device=os.environ.get('DEVICE', 'auto'),  # ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½®çš„è®¾å¤‡
            results_dir=results_dir,
            enable_adaptive_tuning=config.get('enable_adaptive_tuning', True)
        )

        print(f"âœ… StockPredictoråˆå§‹åŒ–å®Œæˆ")
        
        results = predictor.run_prediction_pipeline(
            historical_df=df, # ä¼ å…¥å®Œæ•´çš„å†å²æ•°æ®
            x_df=x_df,
            x_timestamp=x_timestamp,
            y_timestamp=y_timestamp,
            is_future_forecast=is_future_mode,
            symbol=config['symbol'],
            pred_len=pred_len_steps,
            T=config['T'],
            top_p=config['top_p'],
            sample_count=config['sample_count'],
            plot_lookback=lookback_steps,
            enable_advanced_preprocessing=config.get('enable_advanced_preprocessing', False),
            price_normalization=config.get('price_normalization', 'none'),
            trend_adjustment=config.get('trend_adjustment', False),
            volatility_filter=config.get('volatility_filter', False),
            config=config  # ä¼ é€’å®Œæ•´é…ç½®å­—å…¸ç”¨äºå›¾è¡¨è®¾ç½®
        )
    
        if results is None:
            print("âŒ é¢„æµ‹å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
            return

        # === é¢„æµ‹ç»“æœéªŒè¯ ===
        self._validate_prediction_results(results, config, ground_truth)

        # === æ˜ç¡®åŒºåˆ†é¢„æµ‹å’Œå›æµ‹çš„ç»“æœè¾“å‡º ===
        print("="*60)
        
        # === æ–°å¢: ç»“åˆæ¨¡å‹é¢„æµ‹çš„æœ€ç»ˆå»ºè®® ===
        if is_future_mode:
            try:
                # è·å–æ¨¡å‹é¢„æµ‹è¶‹åŠ¿
                pred_start = results['prediction']['close'].iloc[0]
                pred_end = results['prediction']['close'].iloc[-1]
                model_trend = 'up' if pred_end > pred_start else 'down'
                
                # é‡æ–°è®¡ç®—åŒ…å«æ¨¡å‹è¶‹åŠ¿çš„ç»¼åˆåˆ†æ
                tech_df = TechnicalAnalyzer.add_all_indicators(df) # ä½¿ç”¨åŸå§‹dfé‡æ–°è®¡ç®—
                final_analysis = TechnicalAnalyzer.analyze_market_condition(tech_df, model_prediction_trend=model_trend)
                
                print("ğŸ’¡ æ™ºèƒ½äº¤æ˜“å»ºè®® (æ¨¡å‹ + æŠ€æœ¯é¢):")
                print(f"   {final_analysis['advice']}")
                print("="*60)
            except Exception as e:
                print(f"   âš ï¸ ç”Ÿæˆæœ€ç»ˆå»ºè®®å¤±è´¥: {e}")
                
        if is_future_mode:
            print("ğŸ¯ æœªæ¥é¢„æµ‹æ¨¡å¼å®Œæˆï¼")
            print("ğŸ“ ç»“æœä¿å­˜åœ¨ä¸“é—¨çš„é¢„æµ‹æ–‡ä»¶å¤¹ä¸­:")
        else:
            print("ğŸ“Š å†å²å›æµ‹æ¨¡å¼å®Œæˆï¼")
            print("ğŸ“ ç»“æœä¿å­˜åœ¨ä¸“é—¨çš„å›æµ‹æ–‡ä»¶å¤¹ä¸­:")

        print(f"   ğŸ“ˆ å›¾è¡¨æ–‡ä»¶: {os.path.basename(results['files']['plot_path'])}")
        print(f"   ğŸ“„ æ•°æ®æ–‡ä»¶: {os.path.basename(results['files']['csv_path'])}")
        print(f"   ğŸ“‚ å®Œæ•´è·¯å¾„: {os.path.dirname(results['files']['plot_path'])}")
        print("="*60)

    def _generate_future_timestamps(self, last_timestamp, steps, period):
        """
        ç”Ÿæˆæœªæ¥çš„äº¤æ˜“æ—¶é—´æˆ³ (é‡å†™ä»¥ä¿®å¤bug)ã€‚
        """
        from pandas.tseries.offsets import BDay
        
        timestamps = []
        current_time = pd.to_datetime(last_timestamp)
        
        if period == 'D':
            future_days = pd.date_range(start=current_time + BDay(), periods=steps, freq=BDay())
            return future_days

        try:
            minutes_per_step = int(period)
        except ValueError:
            print(f"âŒ é”™è¯¯: æ— æ³•å°†å‘¨æœŸ '{period}' è½¬æ¢ä¸ºåˆ†é’Ÿæ•°ã€‚")
            return None

        while len(timestamps) < steps:
            # 1. æ—¶é—´é€’å¢
            current_time += timedelta(minutes=minutes_per_step)

            # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦è·³åˆ°ä¸‹ä¸€å¤©
            # å¦‚æœå½“å‰æ—¶é—´è¶…è¿‡ä¸‹åˆ3ç‚¹ï¼Œæˆ–è€…è¿›å…¥äº†æ–°çš„ä¸€å¤©
            last_date = timestamps[-1].date() if timestamps else last_timestamp.date()
            if current_time.time() > datetime.strptime("15:00", "%H:%M").time() or \
               current_time.date() > last_date:
                
                # è®¡ç®—ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
                next_day = pd.to_datetime(current_time.date())
                if current_time.weekday() >= 4 or current_time.time() > datetime.strptime("15:00", "%H:%M").time(): # å‘¨äº”æˆ–å‘¨æœ«ï¼Œæˆ–å½“å¤©æ”¶ç›˜å
                    next_day = next_day + BDay()
                
                # é‡ç½®åˆ°ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜æ—¶é—´
                current_time = next_day.replace(hour=9, minute=30, second=0, microsecond=0)

            # 3. å¤„ç†åˆä¼‘ (11:30 -> 13:00)
            if datetime.strptime("11:30", "%H:%M").time() < current_time.time() < datetime.strptime("13:00", "%H:%M").time():
                current_time = current_time.replace(hour=13, minute=0, second=0, microsecond=0)

            # 4. æ£€æŸ¥æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…
            time_of_day = current_time.time()
            is_morning = datetime.strptime("09:30", "%H:%M").time() <= time_of_day <= datetime.strptime("11:30", "%H:%M").time()
            is_afternoon = datetime.strptime("13:00", "%H:%M").time() <= time_of_day <= datetime.strptime("15:00", "%H:%M").time()

            if is_morning or is_afternoon:
                timestamps.append(current_time)
        
        return pd.to_datetime(timestamps)

    def _validate_prediction_results(self, results, config, ground_truth=None):
        """
        éªŒè¯é¢„æµ‹ç»“æœæ˜¯å¦åœ¨åˆç†èŒƒå›´å†…ï¼ŒåŒºåˆ†é¢„æµ‹å’Œå›æµ‹
        
        Args:
            results: é¢„æµ‹ç»“æœå­—å…¸
            config: é…ç½®å­—å…¸
            ground_truth: çœŸå®æ•°æ®(ä»…å›æµ‹æ¨¡å¼),  DataFrame with index as timestamps
        """
        print("="*60)
        
        pred_df = results['prediction']
        analysis = results['analysis']
        is_future_mode = config.get("forecast_future", False)
        
        if is_future_mode:
            # æœªæ¥é¢„æµ‹ï¼šéªŒè¯åˆç†æ€§
            print("ğŸ” æ­£åœ¨éªŒè¯æœªæ¥é¢„æµ‹çš„åˆç†æ€§...")
            self._validate_reasonability(pred_df, analysis)
        else:
            # å›æµ‹ï¼šè®¡ç®—ä¸çœŸå®å€¼çš„å‡†ç¡®æ€§æŒ‡æ ‡
            print("ğŸ” æ­£åœ¨éªŒè¯å›æµ‹å‡†ç¡®æ€§...")
            if ground_truth is None:
                print("   âš ï¸ è­¦å‘Š: å›æµ‹æ¨¡å¼ä½†æœªæä¾›çœŸå®æ•°æ®ï¼Œåªèƒ½è¿›è¡Œåˆç†æ€§éªŒè¯")
                self._validate_reasonability(pred_df, analysis)
            else:
                self._validate_backtest_accuracy(pred_df, ground_truth)
        
        print("="*60)
    
    def _validate_reasonability(self, pred_df, analysis):
        """éªŒè¯é¢„æµ‹åˆç†æ€§ï¼ˆç”¨äºæœªæ¥é¢„æµ‹æˆ–ç¼ºå°‘ground truthçš„æƒ…å†µï¼‰"""
        # è·å–é¢„æµ‹æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
        pred_close = pred_df['close']
        pred_mean = pred_close.mean()
        pred_std = pred_close.std()
        pred_min = pred_close.min()
        pred_max = pred_close.max()

        # è·å–å†å²æ•°æ®çš„æœ€åæ”¶ç›˜ä»·ä½œä¸ºåŸºå‡†
        historical_last_close = analysis['historical_last_close']

        print(f"   - å†å²æœ€åæ”¶ç›˜ä»·: {historical_last_close:.2f}")
        print(f"   - é¢„æµ‹å‡å€¼: {pred_mean:.2f}")
        print(f"   - é¢„æµ‹èŒƒå›´: {pred_min:.2f} - {pred_max:.2f}")

        # è®¡ç®—é¢„æµ‹åå·®
        deviation_percentage = abs(pred_mean - historical_last_close) / historical_last_close * 100

        # è®¾ç½®åˆç†çš„åå·®é˜ˆå€¼ (30%ä»¥å†…è®¤ä¸ºæ˜¯åˆç†çš„)
        max_reasonable_deviation = 30.0

        if deviation_percentage > max_reasonable_deviation:
            print(f"   âš ï¸ è­¦å‘Š: é¢„æµ‹ç»“æœåå·®è¿‡å¤§ ({deviation_percentage:.1f}%)")
            print("   å»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡æˆ–è°ƒæ•´æ¨¡å‹å‚æ•°")
        elif deviation_percentage > 15:
            print(f"   âš ï¸ æ³¨æ„: é¢„æµ‹ç»“æœåå·®ä¸­ç­‰ ({deviation_percentage:.1f}%)")
            print("   å»ºè®®å¾®è°ƒå‚æ•°ä»¥è·å¾—æ›´å‡†ç¡®çš„é¢„æµ‹")
        else:
            print(f"   âœ… é¢„æµ‹ç»“æœåœ¨åˆç†èŒƒå›´å†… (åå·®: {deviation_percentage:.1f}%)")

        # æ£€æŸ¥é¢„æµ‹çš„æ³¢åŠ¨æ€§æ˜¯å¦åˆç†
        volatility_ratio = pred_std / pred_mean
        if volatility_ratio > 0.1:  # å¦‚æœæ³¢åŠ¨ç‡è¶…è¿‡10%
            print(f"   âš ï¸ æ³¨æ„: é¢„æµ‹æ³¢åŠ¨è¾ƒå¤§ (æ³¢åŠ¨ç‡: {volatility_ratio:.1%})")
            print("   å¯èƒ½éœ€è¦é™ä½é‡‡æ ·å‚æ•°ä»¥è·å¾—æ›´ç¨³å®šçš„é¢„æµ‹")
    
    def _validate_backtest_accuracy(self, pred_df, ground_truth):
        """è®¡ç®—å›æµ‹å‡†ç¡®æ€§æŒ‡æ ‡ï¼ˆä¸çœŸå®å†å²æ•°æ®å¯¹æ¯”ï¼‰"""
        import numpy as np
        
        # ç¡®ä¿ç´¢å¼•å¯¹é½
        pred_close = pred_df['close']
        true_close = ground_truth['close']
        
        # è®¡ç®—å„ç§è¯¯å·®æŒ‡æ ‡
        # RMSE (Root Mean Squared Error) - å‡æ–¹æ ¹è¯¯å·®
        rmse = np.sqrt(np.mean((true_close - pred_close) ** 2))
        
        # MAE (Mean Absolute Error) - å¹³å‡ç»å¯¹è¯¯å·®
        mae = np.mean(np.abs(true_close - pred_close))
        
        # MAPE (Mean Absolute Percentage Error) - å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®
        mape = np.mean(np.abs((true_close - pred_close) / true_close)) * 100
        
        # æ–¹å‘å‡†ç¡®ç‡ï¼ˆé¢„æµ‹æ¶¨è·Œæ–¹å‘çš„å‡†ç¡®æ€§ï¼‰
        true_direction = np.sign(true_close.diff().dropna())
        pred_direction = np.sign(pred_close.diff().dropna())
        direction_accuracy = np.mean(true_direction == pred_direction) * 100
        
        print(f"ğŸ“Š å›æµ‹å‡†ç¡®æ€§æŒ‡æ ‡:")
        print(f"   - RMSE (å‡æ–¹æ ¹è¯¯å·®): {rmse:.4f}")
        print(f"   - MAE (å¹³å‡ç»å¯¹è¯¯å·®): {mae:.4f}")
        print(f"   - MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®): {mape:.2f}%")
        print(f"   - æ–¹å‘å‡†ç¡®ç‡: {direction_accuracy:.1f}%")
        
        # è¯„ä¼°å‡†ç¡®æ€§ç­‰çº§
        print(f"\nğŸ“ˆ å‡†ç¡®æ€§è¯„çº§:")
        if mape < 5:
            print(f"   âœ… ä¼˜ç§€ (MAPE < 5%)")
            print(f"   ğŸ¯ é¢„æµ‹éå¸¸å‡†ç¡®ï¼Œå¯ä»¥ä¿¡èµ–è¯¥æ¨¡å‹")
        elif mape < 10:
            print(f"   âœ… è‰¯å¥½ (MAPE < 10%)")
            print(f"   ğŸ‘ é¢„æµ‹è¾ƒä¸ºå‡†ç¡®ï¼Œå¯ä»¥ä½œä¸ºå‚è€ƒ")
        elif mape < 20:
            print(f"   âš ï¸ ä¸€èˆ¬ (MAPE < 20%)")
            print(f"   ğŸ’¡ å»ºè®®è°ƒæ•´æ¨¡å‹å‚æ•°æˆ–å¢åŠ è®­ç»ƒæ•°æ®")
        else:
            print(f"   âŒ è¾ƒå·® (MAPE >= 20%)")
            print(f"   ğŸ”§ å»ºè®®é‡æ–°è°ƒæ•´æ¨¡å‹å‚æ•°æˆ–æ£€æŸ¥æ•°æ®è´¨é‡")
            
        # é¢å¤–çš„ç»†èŠ‚ä¿¡æ¯
        price_range = true_close.max() - true_close.min()
        print(f"\nğŸ“‰ è¯¦ç»†ç»Ÿè®¡:")
        print(f"   - çœŸå®ä»·æ ¼èŒƒå›´: {true_close.min():.2f} - {true_close.max():.2f} (æ³¢åŠ¨: {price_range:.2f})")
        print(f"   - é¢„æµ‹ä»·æ ¼èŒƒå›´: {pred_close.min():.2f} - {pred_close.max():.2f}")
        print(f"   - ç›¸å¯¹è¯¯å·® (RMSE/ä»·æ ¼èŒƒå›´): {rmse/price_range*100:.2f}%")

    def run_tuning(self, config):
        """
        è‡ªåŠ¨è°ƒä¼˜å‚æ•°ï¼šéå†Tå’Œtop_pç»„åˆï¼Œå¯»æ‰¾æœ€ä½³MAPE
        """
        print("ğŸš€ å¼€å§‹è‡ªåŠ¨å‚æ•°è°ƒä¼˜...")
        print("="*60)
        
        # 1. è·å–æ•°æ® (å¤ç”¨ run_prediction çš„é€»è¾‘ - ç®€åŒ–ç‰ˆ)
        lookback_steps = self._calculate_steps(config['lookback_duration'], config['period'])
        pred_len_steps = self._calculate_steps(config['pred_len_duration'], config['period'])
        required_total = lookback_steps + pred_len_steps
        
        print(f"ğŸ“Š æ­£åœ¨è·å–æ•°æ®ç”¨äºè°ƒä¼˜ (å›æº¯: {lookback_steps}, é¢„æµ‹: {pred_len_steps})...")
        
        # è½¬æ¢å‘¨æœŸæ ¼å¼
        period_map = {'5': '5m', '15': '15m', '30': '30m', '60': '60m', 'D': '1d'}
        fetch_period = config['period']
        if config['source'] == 'yfinance':
            fetch_period = period_map.get(config['period'], '1d')

        df, filepath, _ = self.fetcher.get_stock_data(
            symbol=config['symbol'],
            source=config['source'],
            start_date=config['start_date'],
            end_date=config['end_date'],
            period=fetch_period,
            save=True,
            force_refetch=config.get('force_refetch', False),
            min_fresh_days=config.get('min_data_freshness_days'),
            fallback_days=config.get('fallback_fetch_days')
        )
        
        if df is None:
            print(f"âŒ æœªèƒ½è·å–åˆ°æ•°æ®ï¼Œæ— æ³•è¿›è¡Œè°ƒä¼˜ã€‚")
            return

        # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦æ»¡è¶³ç”¨æˆ·è¦æ±‚çš„æœ€ä½æ ‡å‡† (5000)
        if len(df) < 5000:
            print(f"âŒ æ•°æ®é‡ä¸è¶³ ({len(df)})ï¼Œç”¨æˆ·è¦æ±‚æœ€å°‘ 5000 æ¡ã€‚è¯·å°è¯•è·å–æ›´å¤šå†å²æ•°æ®ã€‚")
            return

        if len(df) < required_total:
            print(f"âŒ æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè°ƒä¼˜ (éœ€è¦ {required_total}ï¼Œå®é™… {len(df)})")
            return

        # è£å‰ªæ•°æ®: æœ€å¤šä¿ç•™ 30000 æ¡ (å¤šå¤šç›Šå–„ï¼Œä½†æœ‰ä¸Šé™)
        max_limit = 30000
        if len(df) > max_limit:
            print(f"âœ‚ï¸ æ•°æ®é‡ ({len(df)}) è¶…è¿‡ä¸Šé™ {max_limit}ï¼Œæˆªå–æœ€æ–°çš„ {max_limit} æ¡ç”¨äºè°ƒä¼˜...")
            df = df.tail(max_limit).reset_index(drop=True)
        else:
            print(f"âœ… ä½¿ç”¨å…¨éƒ¨å¯ç”¨æ•°æ® ({len(df)} æ¡) è¿›è¡Œè°ƒä¼˜...")
        
        # 2. å‡†å¤‡å›æµ‹æ•°æ®
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è°ƒæ•´é€»è¾‘ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨ä½¿ç”¨æ›´å¤šçš„æ•°æ®è¿›è¡ŒéªŒè¯ï¼Œè€Œä¸ä»…ä»…æ˜¯æœ€åä¸€æ®µ
        # ä½†ä¸ºäº†ä¿æŒè°ƒä¼˜é€»è¾‘çš„ä¸€è‡´æ€§ï¼ˆé¢„æµ‹æœ€åä¸€æ®µï¼‰ï¼Œæˆ‘ä»¬ä»ç„¶ä½¿ç”¨æœ€åä¸€æ®µä½œä¸ºéªŒè¯é›†
        # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šä½¿ç”¨ df çš„æœ€å required_total é•¿åº¦ä½œä¸ºè¾“å…¥æ¥é¢„æµ‹æœ€åä¸€æ®µ
        # å¦‚æœ df å¾ˆé•¿ï¼Œå‰é¢çš„æ•°æ®å…¶å®æ²¡æœ‰è¢«ç”¨åˆ°é¢„æµ‹é‡Œï¼ˆå› ä¸ºæ¨¡å‹åªçœ‹ lookback_stepsï¼‰
        # ç­‰ç­‰ï¼Œè°ƒä¼˜çš„ç›®çš„æ˜¯æµ‹è¯•å‚æ•°åœ¨"å½“å‰"å¸‚åœºç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚
        # å¦‚æœæˆ‘ä»¬åªè·‘ä¸€æ¬¡é¢„æµ‹ï¼ˆé’ˆå¯¹æœ€åä¸€æ®µï¼‰ï¼Œé‚£ä¹ˆå‰é¢çš„ 20000 æ¡æ•°æ®å…¶å®æ²¡ç”¨ä¸Šï¼Ÿ
        # å¯¹ï¼UnifiedPredictor.run_prediction_pipeline å†…éƒ¨æ˜¯å•æ¬¡é¢„æµ‹ã€‚
        # å¦‚æœè¦åˆ©ç”¨æ›´å¤šæ•°æ®ï¼Œåº”è¯¥è¿›è¡Œ"æ»šåŠ¨å›æµ‹" (Rolling Backtest)ï¼Œä½†è¿™ä¼šéå¸¸æ…¢ã€‚
        # é‰´äºç”¨æˆ·è¯´"å¤šå¤šç›Šå–„"ï¼Œå¯èƒ½è¯¯ä»¥ä¸ºæ•°æ®å¤šå°±èƒ½è·‘å¾—å‡†ã€‚
        # ä½†å®é™…ä¸Šï¼Œå¯¹äºå•æ¬¡é¢„æµ‹ï¼Œåªæœ‰æœ€å lookback_steps æ¡æ•°æ®æ˜¯æœ‰æ•ˆçš„è¾“å…¥ã€‚
        # é™¤é... æˆ‘ä»¬ä¿®æ”¹ run_prediction_pipeline è®©å®ƒè·‘å¤šæ¬¡ï¼Ÿ
        # ä¸ï¼Œé‚£å¤ªå¤æ‚äº†ã€‚
        # æ—¢ç„¶ç”¨æˆ·è¦æ±‚"æ•°æ®æœ€å°‘5000"ï¼Œæˆ‘ä»¬è‡³å°‘ä¿è¯äº†æ•°æ®é‡å……è¶³ã€‚
        # ç°æœ‰çš„é€»è¾‘æ˜¯ï¼š
        # subset_df = df.tail(required_total)
        # è¿™æ„å‘³ç€å®ƒåªç”¨äº†æœ€å required_total æ¡ã€‚
        # å¦‚æœç”¨æˆ·æƒ³åˆ©ç”¨æ›´å¤šæ•°æ®ï¼Œåº”è¯¥æ˜¯æƒ³çœ‹"è¿‡å»ä¸€æ®µæ—¶é—´çš„å¹³å‡è¡¨ç°"ï¼Ÿ
        # ä½†ç›®å‰çš„æ¶æ„ä¸æ”¯æŒå¿«é€Ÿçš„æ»šåŠ¨å›æµ‹ã€‚
        # 
        # è®©æˆ‘ä»¬å…ˆæŒ‰ç”¨æˆ·çš„è¦æ±‚è£å‰ªæ•°æ®ã€‚è™½ç„¶å¯¹äºå•æ¬¡é¢„æµ‹æ¥è¯´ï¼Œå¤šä½™çš„æ•°æ®å¯èƒ½æ²¡è¢«ç›´æ¥ç”¨åˆ°ï¼Œ
        # ä½†ä¿ç•™å®ƒä»¬å¯ä»¥ç¡®ä¿æˆ‘ä»¬æœ‰è¶³å¤Ÿçš„å†å²ä¸Šä¸‹æ–‡ï¼ˆæ¯”å¦‚è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶ï¼‰ã€‚
        
        subset_df = df.tail(required_total).reset_index(drop=True)
        x_df = subset_df.iloc[:lookback_steps][['open', 'high', 'low', 'close', 'volume', 'amount']].copy()
        x_timestamp = subset_df.iloc[:lookback_steps]['timestamps'].copy()
        y_timestamp = subset_df.iloc[lookback_steps:lookback_steps+pred_len_steps]['timestamps'].copy()
        ground_truth = subset_df.iloc[lookback_steps:lookback_steps+pred_len_steps][['open', 'high', 'low', 'close', 'volume', 'amount']].copy()
        ground_truth.index = y_timestamp.values
        
        # 3. å®šä¹‰å‚æ•°ç½‘æ ¼
        T_list = [0.1, 0.3, 0.5, 0.7, 0.9]
        top_p_list = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]
        
        best_mape = float('inf')
        best_params = None
        results = []
        
        total_combinations = len(T_list) * len(top_p_list)
        print(f"ğŸ” å°†æµ‹è¯• {total_combinations} ç»„å‚æ•°ç»„åˆ...")
        print("-" * 60)
        print(f"{'T':<6} | {'top_p':<6} | {'MAPE':<10} | {'Status'}")
        print("-" * 60)
        
        # åˆå§‹åŒ–é¢„æµ‹å™¨
        results_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "tuning_results")
        predictor = StockPredictor(
            device=os.environ.get('DEVICE', 'auto'),
            results_dir=results_dir,
            enable_adaptive_tuning=False # è°ƒä¼˜æ—¶å¿…é¡»å…³é—­è‡ªé€‚åº”
        )
        
        # 4. éå†å‚æ•°
        import numpy as np
        count = 0
        for T in T_list:
            for top_p in top_p_list:
                count += 1
                
                try:
                    # è¿è¡Œé¢„æµ‹
                    # ä¸´æ—¶æŠ‘åˆ¶æ—¥å¿—è¾“å‡ºä»¥ä¿æŒæ•´æ´
                    import logging
                    predictor.logger.setLevel(logging.WARNING)
                    
                    pred_results = predictor.run_prediction_pipeline(
                        historical_df=df,
                        x_df=x_df,
                        x_timestamp=x_timestamp,
                        y_timestamp=y_timestamp,
                        is_future_forecast=False, # å¿…é¡»æ˜¯å›æµ‹æ¨¡å¼
                        symbol=config['symbol'],
                        pred_len=pred_len_steps,
                        T=T,
                        top_p=top_p,
                        sample_count=3, # è°ƒä¼˜æ—¶ä½¿ç”¨è¾ƒå°‘çš„é‡‡æ ·æ•°ä»¥åŠ å¿«é€Ÿåº¦
                        plot_lookback=lookback_steps,
                        enable_advanced_preprocessing=config.get('enable_advanced_preprocessing', False),
                        price_normalization=config.get('price_normalization', 'none'),
                        trend_adjustment=config.get('trend_adjustment', False),
                        volatility_filter=config.get('volatility_filter', False),
                        config=config
                    )
                    
                    predictor.logger.setLevel(logging.INFO) # æ¢å¤æ—¥å¿—
                    
                    if pred_results:
                        pred_df = pred_results['prediction']
                        # è®¡ç®—MAPE
                        true_close = ground_truth['close']
                        pred_close = pred_df['close']
                        mape = np.mean(np.abs((true_close - pred_close) / true_close)) * 100
                        
                        results.append({'T': T, 'top_p': top_p, 'mape': mape})
                        print(f"{T:<6.1f} | {top_p:<6.1f} | {mape:<9.2f}% | âœ…")
                        
                        if mape < best_mape:
                            best_mape = mape
                            best_params = {'T': T, 'top_p': top_p}
                    else:
                        print(f"{T:<6.1f} | {top_p:<6.1f} | {'Failed':<10} | âŒ")
                        
                except Exception as e:
                    print(f"{T:<6.1f} | {top_p:<6.1f} | {'Error':<10} | âŒ ({str(e)})")
        
        print("-" * 60)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        if results:
            import json
            import pandas as pd
            from datetime import datetime
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_dir = os.path.join(results_dir, config['symbol'], 'tuning_reports')
            os.makedirs(report_dir, exist_ok=True)
            
            # 1. ä¿å­˜ä¸º CSV (æ–¹ä¾¿ExcelæŸ¥çœ‹)
            results_df = pd.DataFrame(results)
            results_df = results_df.sort_values('mape') # æŒ‰æ•ˆæœæ’åº
            csv_path = os.path.join(report_dir, f"tuning_results_{timestamp}.csv")
            results_df.to_csv(csv_path, index=False)
            
            # 2. ä¿å­˜æœ€ä½³å‚æ•°ä¸º JSON
            best_result = results_df.iloc[0].to_dict()
            json_path = os.path.join(report_dir, f"best_params_{timestamp}.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(best_result, f, indent=4, ensure_ascii=False)
                
            print(f"\nğŸ“„ è¯¦ç»†è°ƒä¼˜æŠ¥å‘Šå·²ä¿å­˜:")
            print(f"   - CSVè¡¨æ ¼: {csv_path}")
            print(f"   - æœ€ä½³å‚æ•°: {json_path}")

        if best_params:
            print(f"\nğŸ† è°ƒä¼˜å®Œæˆï¼æœ€ä½³å‚æ•°ç»„åˆ:")
            print(f"   T = {best_params['T']}")
            print(f"   top_p = {best_params['top_p']}")
            print(f"   æœ€ä½³ MAPE = {best_mape:.2f}%")
            print("\nğŸ’¡ å»ºè®®æ›´æ–° run_my_prediction.py ä¸­çš„ PREDICTION_CONFIG:")
            print(f"    \"T\": {best_params['T']},")
            print(f"    \"top_p\": {best_params['top_p']},")
        else:
            print("\nâŒ è°ƒä¼˜å¤±è´¥ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°ç»„åˆã€‚")
            print("="*60)

    def _estimate_required_days(self, required_points, period):
        """æ ¹æ®å‘¨æœŸä¼°ç®—éœ€è¦çš„æœ€å°‘äº¤æ˜“æ—¥æ•°"""
        if required_points <= 0:
            return 1

        if period == 'D':
            return max(required_points, 1)

        try:
            minutes_per_step = int(period)
            if minutes_per_step <= 0:
                raise ValueError
            steps_per_day = max(TRADING_MINUTES_PER_DAY // minutes_per_step, 1)
            return max(math.ceil(required_points / steps_per_day), 1)
        except ValueError:
            return max(required_points, 1)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Kronos è‚¡ç¥¨é¢„æµ‹ç»Ÿä¸€è„šæœ¬")
    parser.add_argument(
        "--mode",
        choices=["future", "backtest", "tune"],
        default="future",
        help="é€‰æ‹©æ‰§è¡Œæ¨¡å¼: future=é¢„æµ‹æœªæ¥, backtest=å†å²å›æµ‹, tune=è‡ªåŠ¨å‚æ•°è°ƒä¼˜"
    )
    # ç½‘ç»œæ¨¡å¼äº’æ–¥ç»„
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        "--offline",
        action="store_true",
        help="å¯ç”¨ç¦»çº¿æ¨¡å¼ï¼Œåªä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹ï¼Œä¸å°è¯•ç½‘ç»œæ›´æ–°"
    )
    mode_group.add_argument(
        "--online",
        action="store_true",
        help="å¯ç”¨åœ¨çº¿æ¨¡å¼ï¼Œå°è¯•æ›´æ–°æ¨¡å‹ï¼Œå¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰"
    )
    parser.add_argument(
        "--force-update",
        action="store_true",
        help="å¼ºåˆ¶æ›´æ–°æ¨¡å‹ï¼Œå¿½ç•¥æ›´æ–°é—´éš”æ£€æŸ¥"
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_arguments()
    runtime_config = PREDICTION_CONFIG.copy()
    
    # æ¨¡å¼å¤„ç†
    if args.mode == "tune":
        # è°ƒä¼˜æ¨¡å¼å¼ºåˆ¶ä¸ºå›æµ‹é€»è¾‘
        is_future_mode = False
        runtime_config["forecast_future"] = False
        mode_label = "ğŸ›ï¸ è‡ªåŠ¨å‚æ•°è°ƒä¼˜æ¨¡å¼"
        mode_desc = "è‡ªåŠ¨å¯»æ‰¾æœ€ä½³ T å’Œ top_p å‚æ•°ç»„åˆ"
        result_folder = "tuning_results"
    else:
        is_future_mode = args.mode == "future"
        runtime_config["forecast_future"] = is_future_mode
        
        if is_future_mode:
            mode_label = "ğŸ¯ æœªæ¥é¢„æµ‹æ¨¡å¼"
            mode_desc = "åŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥è‚¡ä»·èµ°åŠ¿"
            result_folder = "future_forecast"
        else:
            mode_label = "ğŸ“Š å†å²å›æµ‹æ¨¡å¼"
            mode_desc = "ä½¿ç”¨å†å²æ•°æ®éªŒè¯é¢„æµ‹å‡†ç¡®æ€§"
            result_folder = "backtest"

    # è®¾ç½®æ¨¡å‹åŠ è½½æ¨¡å¼
    if args.offline:
        os.environ['KRONOS_OFFLINE_MODE'] = 'true'
        print("ğŸ”Œ å¯ç”¨ç¦»çº¿æ¨¡å¼: åªä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹")
    elif args.online or args.force_update:
        os.environ['KRONOS_OFFLINE_MODE'] = 'false'
        if args.force_update:
            os.environ['KRONOS_FORCE_UPDATE'] = 'true'
            print("ğŸ”„ å¯ç”¨å¼ºåˆ¶æ›´æ–°æ¨¡å¼: å°†å¼ºåˆ¶ä¸‹è½½æœ€æ–°æ¨¡å‹")
        else:
            print("ğŸŒ å¯ç”¨åœ¨çº¿æ¨¡å¼: æ™ºèƒ½æ£€æŸ¥æ›´æ–°ï¼Œå¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜")
    else:
        # é»˜è®¤åœ¨çº¿æ¨¡å¼
        os.environ['KRONOS_OFFLINE_MODE'] = 'false'

    print("="*60)
    print(f"   {mode_label}")
    print(f"   {mode_desc}")
    if args.mode != "tune":
        print(f"   ğŸ“ ç»“æœå°†ä¿å­˜è‡³: prediction_results/{runtime_config['symbol']}/{result_folder}/")
    print("="*60)
    
    predictor = UnifiedPredictor()
    if args.mode == "tune":
        predictor.run_tuning(runtime_config)
    else:
        predictor.run_prediction(runtime_config)
